diff -ruNP linux-2.6.18.orig/include/linux/skbuff.h linux-2.6.18/include/linux/skbuff.h
--- linux-2.6.18.orig/include/linux/skbuff.h	2006-09-20 05:42:06.000000000 +0200
+++ linux-2.6.18/include/linux/skbuff.h	2006-11-06 21:23:47.000000000 +0100
@@ -30,6 +30,10 @@
 #include <net/checksum.h>
 #include <linux/dmaengine.h>
 
+#ifdef CONFIG_IP_LEF
+#include <net/lef_struct.h>
+#endif
+
 #define HAVE_ALLOC_SKB		/* For the drivers to know */
 #define HAVE_ALIGNABLE_SKB	/* Ditto 8)		   */
 
@@ -261,6 +265,9 @@
 
 	struct  dst_entry	*dst;
 	struct	sec_path	*sp;
+#ifdef CONFIG_IP_LEF
+	struct  lef		lef;
+#endif
 
 	/*
 	 * This is the control buffer. It is free to use for every
diff -ruNP linux-2.6.18.orig/include/net/lef.h linux-2.6.18/include/net/lef.h
--- linux-2.6.18.orig/include/net/lef.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.18/include/net/lef.h	2006-11-06 21:48:26.000000000 +0100
@@ -0,0 +1,64 @@
+/*
+ * Linux express forwarding code
+ *
+ * Mainly developed by krichy < krichy at cflinux dot hu >
+ *
+ * Currently it is under development, so do not expect much from it,
+ * or not anything else than a kernel panic. :)
+ *
+ * The code is subject to GPLv2 or any later one.
+ */
+
+#ifndef _NET_LEF_H
+#define _NET_LEF_H
+
+#include <asm/types.h>
+#include <asm/processor.h>
+#include <net/neighbour.h>
+#include <linux/netdevice.h>
+#include <net/neighbour.h>
+#include <net/lef_struct.h>
+
+// some trivial lef-related functions
+
+/* lef_init
+ * is called when initialising a lef structure
+ * it just zeros all elements of it
+ * @l: struct lef
+ */
+static inline void		lef_init(struct lef* l)
+{
+	memset(l, 0, sizeof(*l));
+}
+
+/* lef_init_copy
+ * inits a lef from another one (actually copying old contents
+ * and allocating references
+ * @l: new lef
+ * @o: old lef
+ */
+static inline void		lef_init_copy(struct lef* l, const struct lef* o)
+{
+	l->gateway = o->gateway;
+	if ((l->dev = o->dev))
+		dev_hold(l->dev);
+	l->mtu = o->mtu;
+	if ((l->neighbour = o->neighbour))
+		neigh_hold(l->neighbour);
+}
+
+/* lef_destroy
+ * destroys (frees) elements of a lef
+ * @l: struct lef
+ */
+static inline void		lef_destroy(struct lef* l)
+{
+	if (likely(l->neighbour))
+		neigh_release(l->neighbour);
+	if (likely(l->dev))
+		dev_put(l->dev);
+}
+
+extern int			lef_forward(struct sk_buff *);
+
+#endif /* _NET_LEF_H */
diff -ruNP linux-2.6.18.orig/include/net/lef_struct.h linux-2.6.18/include/net/lef_struct.h
--- linux-2.6.18.orig/include/net/lef_struct.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.18/include/net/lef_struct.h	2006-11-06 21:23:37.000000000 +0100
@@ -0,0 +1,27 @@
+/*
+ * Linux express forwarding code
+ *
+ * Mainly developed by krichy < krichy at cflinux dot hu >
+ *
+ * Currently it is under development, so do not expect much from it,
+ * or not anything else than a kernel panic. :)
+ *
+ * The code is subject to GPLv2 or any later one.
+ */
+
+#ifndef _NET_LEF_STRUCT_H
+#define _NET_LEF_STRUCT_H
+
+// forward declarations
+struct net_device;
+struct neighbour;
+
+// our express forwarding structure
+struct lef {
+	__u32			gateway;	// our gateway
+	struct net_device	*dev;		// our device
+	u32			mtu;		// our mtu
+	struct neighbour	*neighbour;	// our neigbour
+};
+
+#endif /* _NET_LEF_STRUCT_H */
--- linux-2.6.20.3/net/core/skbuff.c.orig	2007-03-20 21:40:26.000000000 +0100
+++ linux-2.6.20.3/net/core/skbuff.c	2007-03-20 21:41:25.000000000 +0100
@@ -66,6 +66,10 @@
 #include <asm/uaccess.h>
 #include <asm/system.h>
 
+#ifdef CONFIG_IP_LEF
+#include <net/lef.h>
+#endif
+
 #include "kmap_skb.h"
 
 static struct kmem_cache *skbuff_head_cache __read_mostly;
@@ -373,6 +377,9 @@
 #ifdef CONFIG_XFRM
 	secpath_put(skb->sp);
 #endif
+#ifdef CONFIG_IP_LEF
+	lef_destroy(&skb->lef);
+#endif
 	if (skb->destructor) {
 		WARN_ON(in_irq());
 		skb->destructor(skb);
@@ -462,6 +469,9 @@
 #ifdef CONFIG_INET
 	secpath_get(skb->sp);
 #endif
+#ifdef CONFIG_IP_LEF
+	lef_init_copy(&n->lef, &skb->lef);
+#endif
 	memcpy(n->cb, skb->cb, sizeof(skb->cb));
 	C(len);
 	C(data_len);
@@ -529,6 +539,9 @@
 #ifdef CONFIG_INET
 	new->sp		= secpath_get(old->sp);
 #endif
+#ifdef CONFIG_IP_LEF
+	lef_init_copy(&new->lef, &old->lef);
+#endif
 	new->h.raw	= old->h.raw + offset;
 	new->nh.raw	= old->nh.raw + offset;
 	new->mac.raw	= old->mac.raw + offset;
@@ -1979,6 +1992,9 @@
 		nskb->priority = skb->priority;
 		nskb->protocol = skb->protocol;
 		nskb->dst = dst_clone(skb->dst);
+#ifdef CONFIG_IP_LEF
+		lef_init_copy(&nskb->lef, &skb->lef);
+#endif
 		memcpy(nskb->cb, skb->cb, sizeof(skb->cb));
 		nskb->pkt_type = skb->pkt_type;
 		nskb->mac_len = skb->mac_len;
diff -ruNP linux-2.6.18.orig/net/ipv4/arp.c linux-2.6.18/net/ipv4/arp.c
--- linux-2.6.18.orig/net/ipv4/arp.c	2006-09-20 05:42:06.000000000 +0200
+++ linux-2.6.18/net/ipv4/arp.c	2006-11-06 20:15:27.000000000 +0100
@@ -127,6 +127,10 @@
 
 #include <linux/netfilter_arp.h>
 
+#ifdef CONFIG_IP_LEF
+#include <net/lef.h>
+#endif
+
 /*
  *	Interface to generic neighbour cache.
  */
@@ -526,6 +530,31 @@
 	return 0;
 }
 
+#ifdef CONFIG_IP_LEF
+int arp_bind_neighbour_lef(struct lef *lef)
+{
+	struct net_device *dev = lef->dev;
+	struct neighbour *n = lef->neighbour;
+
+	if (dev == NULL)
+		return -EINVAL;
+	if (n == NULL) {
+		u32 nexthop = lef->gateway;
+		if (dev->flags&(IFF_LOOPBACK|IFF_POINTOPOINT))
+			nexthop = 0;
+		n = __neigh_lookup_errno(
+#if defined(CONFIG_ATM_CLIP) || defined(CONFIG_ATM_CLIP_MODULE)
+		    dev->type == ARPHRD_ATM ? clip_tbl_hook :
+#endif
+		    &arp_tbl, &nexthop, dev);
+		if (IS_ERR(n))
+			return PTR_ERR(n);
+		lef->neighbour = n;
+	}
+	return 0;
+}
+#endif
+
 /*
  * Check if we can use proxy ARP for this path
  */
--- linux-2.6.20.3/net/ipv4/Kconfig.orig	2007-03-20 21:40:26.000000000 +0100
+++ linux-2.6.20.3/net/ipv4/Kconfig	2007-03-20 21:40:26.000000000 +0100
@@ -51,6 +51,12 @@
 
 	  If unsure, say N here.
 
+config IP_LEF
+	bool "IP: Linux express forwarding"
+	depends on IP_ADVANCED_ROUTER && !SMP && PREEMPT_NONE
+	---help---
+	You should not turn this on
+
 choice 
 	prompt "Choose IP: FIB lookup algorithm (choose FIB_HASH if unsure)"
 	depends on IP_ADVANCED_ROUTER
@@ -85,6 +91,11 @@
 	---help---
 	Radix based FIB lookup algorithm. Much simpler than the trie, and a bit faster.
      
+config IP_FIB_LEF
+	bool "FIB_LEF"
+	---help---
+	An improved radix based IPv4 lookup algorithm. This needs much testing.
+
 endchoice
 
 config IP_FIB_HASH
@@ -92,7 +103,7 @@
 
 config IP_MULTIPLE_TABLES
 	bool "IP: policy routing"
-	depends on IP_ADVANCED_ROUTER
+	depends on IP_ADVANCED_ROUTER && !IP_LEF
 	select FIB_RULES
 	---help---
 	  Normally, a router decides what to do with a received packet based
@@ -123,7 +134,7 @@
 
 config IP_ROUTE_MULTIPATH_CACHED
 	bool "IP: equal cost multipath with caching support (EXPERIMENTAL)"
-	depends on IP_ROUTE_MULTIPATH
+	depends on IP_ROUTE_MULTIPATH && !IP_LEF
 	help
 	  Normally, equal cost multipath routing is not supported by the
 	  routing cache. If you say Y here, alternative routes are cached
--- a/net/ipv4/Makefile	2006-12-18 09:27:06.000000000 +0100
+++ linux-2.6.19/net/ipv4/Makefile	2006-12-18 09:31:45.000000000 +0100
@@ -14,6 +14,7 @@
 obj-$(CONFIG_IP_FIB_HASH) += fib_hash.o
 obj-$(CONFIG_IP_FIB_TRIE) += fib_trie.o
 obj-$(CONFIG_IP_FIB_RADIX) += fib_radix.o
+obj-$(CONFIG_IP_FIB_LEF) += fib_lef.o
 obj-$(CONFIG_PROC_FS) += proc.o
 obj-$(CONFIG_IP_MULTIPLE_TABLES) += fib_rules.o
 obj-$(CONFIG_IP_MROUTE) += ipmr.o
@@ -50,6 +51,7 @@
 obj-$(CONFIG_TCP_CONG_SCALABLE) += tcp_scalable.o
 obj-$(CONFIG_TCP_CONG_LP) += tcp_lp.o
 obj-$(CONFIG_NETLABEL) += cipso_ipv4.o
+obj-$(CONFIG_IP_LEF) += lef.o
 
 obj-$(CONFIG_XFRM) += xfrm4_policy.o xfrm4_state.o xfrm4_input.o \
 		      xfrm4_output.o
--- linux-2.6.20.3/include/net/arp.h.orig	2007-03-13 19:27:08.000000000 +0100
+++ linux-2.6.20.3/include/net/arp.h	2007-03-20 21:48:48.000000000 +0100
@@ -16,6 +16,9 @@
 			 struct net_device *dev, __be32 src_ip,
 			 unsigned char *dest_hw, unsigned char *src_hw, unsigned char *th);
 extern int	arp_bind_neighbour(struct dst_entry *dst);
+#ifdef CONFIG_IP_LEF
+extern int	arp_bind_neighbour_lef(struct lef *);
+#endif
 extern int	arp_mc_map(__be32 addr, u8 *haddr, struct net_device *dev, int dir);
 extern void	arp_ifdown(struct net_device *dev);
 
--- linux-2.6.18.orig/net/ipv4/icmp.c	2006-09-20 05:42:06.000000000 +0200
+++ linux-2.6.18/net/ipv4/icmp.c	2006-11-11 16:34:39.000000000 +0100
@@ -439,8 +439,10 @@
 	u32 saddr;
 	u8  tos;
 
+#ifndef CONFIG_IP_LEF
 	if (!rt)
 		goto out;
+#endif
 
 	/*
 	 *	Find the original header. It is expected to be valid, of course.
@@ -461,7 +463,11 @@
 	/*
 	 *	Now check at the protocol level
 	 */
+#ifdef CONFIG_IP_LEF
+	if (rt && rt->rt_flags & (RTCF_BROADCAST | RTCF_MULTICAST))
+#else
 	if (rt->rt_flags & (RTCF_BROADCAST | RTCF_MULTICAST))
+#endif
 		goto out;
 
 	/*
@@ -511,7 +517,11 @@
 	 */
 
 	saddr = iph->daddr;
+#ifdef CONFIG_IP_LEF
+	if (!rt || !(rt->rt_flags & RTCF_LOCAL)) {
+#else
 	if (!(rt->rt_flags & RTCF_LOCAL)) {
+#endif
 		if (sysctl_icmp_errors_use_inbound_ifaddr)
 			saddr = inet_select_addr(skb_in->dev, 0, RT_SCOPE_LINK);
 		else
--- linux-2.6.20.3/net/ipv4/netfilter/Kconfig.orig	2007-03-13 19:27:08.000000000 +0100
+++ linux-2.6.20.3/net/ipv4/netfilter/Kconfig	2007-03-20 21:46:59.000000000 +0100
@@ -421,7 +421,7 @@
 
 config IP_NF_TARGET_MASQUERADE
 	tristate "MASQUERADE target support"
-	depends on (NF_NAT || IP_NF_NAT)
+	depends on (NF_NAT || IP_NF_NAT) && !IP_LEF
 	help
 	  Masquerading is a special case of NAT: all outgoing connections are
 	  changed to seem to come from a particular interface's address, and
--- linux-2.6.19/include/net/route.h.orig	2006-11-29 22:57:37.000000000 +0100
+++ linux-2.6.19/include/net/route.h	2006-12-03 10:34:38.000000000 +0100
@@ -117,6 +117,9 @@
 extern int		ip_route_output_key(struct rtable **, struct flowi *flp);
 extern int		ip_route_output_flow(struct rtable **rp, struct flowi *flp, struct sock *sk, int flags);
 extern int		ip_route_input(struct sk_buff*, __be32 dst, __be32 src, u8 tos, struct net_device *devin);
+#ifdef CONFIG_IP_LEF
+extern int		ip_route_input_lef(struct sk_buff*, __be32 dst, __be32 src, u8 tos, struct net_device *devin, int use_lef);
+#endif
 extern unsigned short	ip_rt_frag_needed(struct iphdr *iph, unsigned short new_mtu);
 extern void		ip_rt_send_redirect(struct sk_buff *skb);
 
--- linux-2.6.19.orig/net/ipv4/route.c	2006-11-29 22:57:37.000000000 +0100
+++ linux-2.6.19/net/ipv4/route.c	2006-12-09 19:07:27.000000000 +0100
@@ -108,6 +108,9 @@
 #ifdef CONFIG_SYSCTL
 #include <linux/sysctl.h>
 #endif
+#ifdef CONFIG_IP_LEF
+#include <net/lef.h>
+#endif
 
 #define RT_FL_TOS(oldflp) \
     ((u32)(oldflp->fl4_tos & (IPTOS_RT_MASK | RTO_ONLINK)))
@@ -252,6 +255,15 @@
 #define RT_CACHE_STAT_INC(field) \
 	(__raw_get_cpu_var(rt_cache_stat).field++)
 
+#ifdef CONFIG_IP_LEF
+static inline int rt_intern_hash(unsigned hash, struct rtable *rth,
+				struct rtable **res);
+
+static inline unsigned int rt_hash_code(u32 daddr, u32 saddr)
+{
+	return 0;
+}
+#else
 static int rt_intern_hash(unsigned hash, struct rtable *rth,
 				struct rtable **res);
 
@@ -260,6 +272,7 @@
 	return (jhash_2words(daddr, saddr, rt_hash_rnd)
 		& rt_hash_mask);
 }
+#endif
 
 #define rt_hash(daddr, saddr, idx) \
 	rt_hash_code((__force u32)(__be32)(daddr),\
@@ -922,6 +935,23 @@
 out:	return 0;
 }
 
+#ifdef CONFIG_IP_LEF
+static inline int rt_intern_hash(unsigned hash, struct rtable *rt, struct rtable **rp)
+{
+	int err;
+
+	err = arp_bind_neighbour(&rt->u.dst);
+	if (err) {
+		rt_drop(rt);
+		return err;
+	}
+
+	rt_free(rt);
+	*rp = rt;
+
+	return 0;
+}
+#else
 static int rt_intern_hash(unsigned hash, struct rtable *rt, struct rtable **rp)
 {
 	struct rtable	*rth, **rthp;
@@ -1052,6 +1082,7 @@
 	*rp = rt;
 	return 0;
 }
+#endif
 
 void rt_bind_peer(struct rtable *rt, int create)
 {
@@ -1721,7 +1752,11 @@
 				  struct fib_result* res, 
 				  struct in_device *in_dev, 
 				  __be32 daddr, __be32 saddr, u32 tos,
-				  struct rtable **result) 
+				  struct rtable **result
+#ifdef CONFIG_IP_LEF
+				  , int use_lef
+#endif
+				  )
 {
 
 	struct rtable *rth;
@@ -1740,6 +1775,9 @@
 		return -EINVAL;
 	}
 
+#ifdef CONFIG_IP_LEF
+	if (!use_lef || IN_DEV_RPFILTER(in_dev)) {
+#endif
 
 	err = fib_validate_source(saddr, daddr, tos, FIB_RES_OIF(*res), 
 				  in_dev->dev, &spec_dst, &itag);
@@ -1758,6 +1796,9 @@
 	    (IN_DEV_SHARED_MEDIA(out_dev) ||
 	     inet_addr_onlink(out_dev, saddr, FIB_RES_GW(*res))))
 		flags |= RTCF_DOREDIRECT;
+#ifdef CONFIG_IP_LEF
+	}
+#endif
 
 	if (skb->protocol != htons(ETH_P_IP)) {
 		/* Not IP (i.e. ARP). Do not create route, if it is
@@ -1769,6 +1810,25 @@
 		}
 	}
 
+#ifdef CONFIG_IP_LEF
+	if (use_lef) {
+		if (likely(res->nh->neighbour)) {
+			skb->lef.neighbour = res->nh->neighbour;
+			atomic_inc(&skb->lef.neighbour->refcnt);
+		} else {
+			if (FIB_RES_GW(*res) &&
+					FIB_RES_NH(*res).nh_scope == RT_SCOPE_LINK)
+				skb->lef.gateway = FIB_RES_GW(*res);
+			else
+				skb->lef.gateway = daddr;
+		}
+		skb->lef.dev = (out_dev)->dev;
+		dev_hold(skb->lef.dev);
+		skb->lef.mtu = res->fi->fib_mtu ? res->fi->fib_mtu : skb->lef.dev->mtu;
+		err = 0;
+		goto cleanup;
+	}
+#endif
 
 	rth = dst_alloc(&ipv4_dst_ops);
 	if (!rth) {
@@ -1834,7 +1894,11 @@
 #endif
 
 	/* create a routing cache entry */
+#ifdef CONFIG_IP_LEF
+	err = __mkroute_input(skb, res, in_dev, daddr, saddr, tos, &rth, 0);
+#else
 	err = __mkroute_input(skb, res, in_dev, daddr, saddr, tos, &rth);
+#endif
 	if (err)
 		return err;
 
@@ -1910,8 +1974,13 @@
  *	2. IP spoofing attempts are filtered with 100% of guarantee.
  */
 
-static int ip_route_input_slow(struct sk_buff *skb, __be32 daddr, __be32 saddr,
+#ifdef CONFIG_IP_LEF
+static inline int ip_route_input_slow(struct sk_buff *skb, __be32 daddr, __be32 saddr,
+			       u8 tos, struct net_device *dev, int use_lef)
+#else
+static inline int ip_route_input_slow(struct sk_buff *skb, __be32 daddr, __be32 saddr,
 			       u8 tos, struct net_device *dev)
+#endif
 {
 	struct fib_result res;
 	struct in_device *in_dev = in_dev_get(dev);
@@ -1990,6 +2059,33 @@
 	if (res.type != RTN_UNICAST)
 		goto martian_destination;
 
+#ifdef CONFIG_IP_LEF
+	if (likely(use_lef)) {
+		if (likely((res.nh->neighbour) && !IN_DEV_RPFILTER(in_dev))) {
+			skb->lef.neighbour = res.nh->neighbour;
+			atomic_inc(&skb->lef.neighbour->refcnt);
+			skb->lef.dev = FIB_RES_DEV(res);
+			dev_hold(skb->lef.dev);
+			skb->lef.mtu = res.fi->fib_mtu ? res.fi->fib_mtu : skb->lef.dev->mtu;
+			goto done;
+		}
+
+		err = __mkroute_input(skb, &res, in_dev, daddr, saddr, tos, NULL, 1);
+		if (unlikely(err))
+			goto done;
+
+		if (unlikely(!(skb->lef.neighbour))) {
+			err = arp_bind_neighbour_lef(&skb->lef);
+			if (unlikely(err))
+				goto done;
+			if (skb->lef.gateway && skb->lef.gateway != daddr) { // only store if it is a really gateway
+				res.nh->neighbour = skb->lef.neighbour;
+				atomic_inc(&res.nh->neighbour->refcnt);
+			}
+		}
+		goto done;
+	}
+#endif
 	err = ip_mkroute_input(skb, &res, &fl, in_dev, daddr, saddr, tos);
 	if (err == -ENOBUFS)
 		goto e_nobufs;
@@ -2096,14 +2192,22 @@
 	goto e_inval;
 }
 
+#ifdef CONFIG_IP_LEF
+int ip_route_input_lef(struct sk_buff *skb, __be32 daddr, __be32 saddr,
+		   u8 tos, struct net_device *dev, int use_lef)
+#else
 int ip_route_input(struct sk_buff *skb, __be32 daddr, __be32 saddr,
 		   u8 tos, struct net_device *dev)
+#endif
 {
+#ifndef CONFIG_IP_LEF
 	struct rtable * rth;
 	unsigned	hash;
 	int iif = dev->ifindex;
+#endif
 
 	tos &= IPTOS_RT_MASK;
+#ifndef CONFIG_IP_LEF
 	hash = rt_hash(daddr, saddr, iif);
 
 	rcu_read_lock();
@@ -2128,6 +2232,7 @@
 		RT_CACHE_STAT_INC(in_hlist_search);
 	}
 	rcu_read_unlock();
+#endif /* !CONFIG_IP_LEF */
 
 	/* Multicast recognition logic is moved from route cache to here.
 	   The problem was that too many Ethernet cards have broken/missing
@@ -2160,8 +2265,21 @@
 		rcu_read_unlock();
 		return -EINVAL;
 	}
+#ifdef CONFIG_IP_LEF
+	return ip_route_input_slow(skb, daddr, saddr, tos, dev, use_lef);
+#else
 	return ip_route_input_slow(skb, daddr, saddr, tos, dev);
+#endif
+}
+
+#ifdef CONFIG_IP_LEF
+int ip_route_input(struct sk_buff *skb, u32 daddr, u32 saddr,
+		   u8 tos, struct net_device *dev)
+{
+	return ip_route_input_lef(skb, daddr, saddr, tos, dev, 0);
 }
+#endif
+
 
 static inline int __mkroute_output(struct rtable **result,
 				   struct fib_result* res, 
@@ -2571,6 +2689,7 @@
 
 int __ip_route_output_key(struct rtable **rp, const struct flowi *flp)
 {
+#ifndef CONFIG_IP_LEF
 	unsigned hash;
 	struct rtable *rth;
 
@@ -2610,6 +2729,7 @@
 		RT_CACHE_STAT_INC(out_hlist_search);
 	}
 	rcu_read_unlock_bh();
+#endif
 
 	return ip_route_output_slow(rp, flp);
 }
@@ -3215,6 +3335,9 @@
 	xfrm_init();
 	xfrm4_init();
 #endif
+#ifdef CONFIG_IP_LEF
+	printk(KERN_DEBUG "IPv4: LEF v0.2 is active\n");
+#endif
 	return rc;
 }
 
--- linux-2.6.18.orig/net/core/neighbour.c	2006-09-20 05:42:06.000000000 +0200
+++ linux-2.6.18/net/core/neighbour.c	2006-11-14 13:33:31.000000000 +0100
@@ -34,6 +34,10 @@
 #include <linux/random.h>
 #include <linux/string.h>
 
+#ifdef CONFIG_IP_LEF
+#include <net/lef.h>
+#endif
+
 #define NEIGH_DEBUG 1
 
 #define NEIGH_PRINTK(x...) printk(x)
@@ -1139,7 +1143,11 @@
 	struct neighbour *neigh;
 	int rc = 0;
 
+#ifdef CONFIG_IP_LEF
+	if ((!dst || !(neigh = dst->neighbour)) && !(neigh = skb->lef.neighbour))
+#else
 	if (!dst || !(neigh = dst->neighbour))
+#endif
 		goto discard;
 
 	__skb_pull(skb, skb->nh.raw - skb->data);
@@ -1147,7 +1155,11 @@
 	if (!neigh_event_send(neigh, skb)) {
 		int err;
 		struct net_device *dev = neigh->dev;
+#ifdef CONFIG_IP_LEF
+		if (dst && dev->hard_header_cache && !dst->hh) {
+#else
 		if (dev->hard_header_cache && !dst->hh) {
+#endif
 			write_lock_bh(&neigh->lock);
 			if (!dst->hh)
 				neigh_hh_init(neigh, dst, dst->ops->protocol);
@@ -1182,8 +1194,17 @@
 {
 	int err;
 	struct dst_entry *dst = skb->dst;
-	struct neighbour *neigh = dst->neighbour;
-	struct net_device *dev = neigh->dev;
+	struct neighbour *neigh;
+	struct net_device *dev;
+
+#ifdef CONFIG_IP_LEF
+	if (!dst)
+		neigh = skb->lef.neighbour;
+	else
+#endif
+		neigh = dst->neighbour;
+
+	dev = neigh->dev;
 
 	__skb_pull(skb, skb->nh.raw - skb->data);
 
--- linux-2.6.18.orig/net/ipv4/lef.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.18/net/ipv4/lef.c	2006-11-14 13:48:09.000000000 +0100
@@ -0,0 +1,124 @@
+/*
+ * Linux express forwarding code
+ *
+ * Mainly developed by krichy < krichy at cflinux dot hu >
+ *
+ * Currently it is under development, so do not expect much from it,
+ * or not anything else than a kernel panic. :)
+ *
+ * The code is subject to GPLv2 or any later one.
+ */
+
+#include <linux/skbuff.h>
+#include <linux/netdevice.h>
+#include <net/arp.h>
+#include <net/lef.h>
+#include <net/sock.h>
+#include <net/ip.h>
+#include <net/route.h>
+#include <net/icmp.h>
+#include <linux/icmp.h>
+#include <linux/netfilter_ipv4.h>
+#include <linux/netfilter_bridge.h>
+
+static inline int	lef_output_finish2(struct sk_buff *skb)
+{
+	struct net_device *dev = skb->lef.dev;
+	struct neighbour *neigh;
+	int hh_len = LL_RESERVED_SPACE(dev);
+
+	/* Be paranoid, rather than too clever. */
+	if (unlikely(skb_headroom(skb) < hh_len && dev->hard_header)) {
+		struct sk_buff *skb2;
+
+		skb2 = skb_realloc_headroom(skb, LL_RESERVED_SPACE(dev));
+		if (skb2 == NULL) {
+			kfree_skb(skb);
+			return -ENOMEM;
+		}
+		if (skb->sk)
+			skb_set_owner_w(skb2, skb->sk);
+		kfree_skb(skb);
+		skb = skb2;
+	}
+
+	if (likely((neigh = skb->lef.neighbour))) {
+		return neigh->output(skb);
+	}
+
+	printk("lef_output_finish2: no neighbour found\n");
+	kfree_skb(skb);
+
+	return NET_RX_DROP;
+}
+
+static inline int	lef_output_finish(struct sk_buff *skb)
+{
+	if (skb->len > skb->lef.mtu && !skb_is_gso(skb)) {
+		// TODO: fragment
+		kfree_skb(skb);
+		return NET_RX_DROP;
+	} else {
+		return lef_output_finish2(skb);
+	}
+}
+
+static inline int	lef_output(struct sk_buff *skb)
+{
+	struct net_device *dev = skb->lef.dev;
+
+	IP_INC_STATS(IPSTATS_MIB_OUTREQUESTS);
+
+	skb->dev = dev;
+	skb->protocol = htons(ETH_P_IP);
+
+	return NF_HOOK_COND(PF_INET, NF_IP_POST_ROUTING, skb, NULL, dev,
+		            lef_output_finish,
+			    !(IPCB(skb)->flags & IPSKB_REROUTED));
+}
+
+static inline int	lef_forward_finish(struct sk_buff *skb)
+{
+	IP_INC_STATS_BH(IPSTATS_MIB_OUTFORWDATAGRAMS);
+
+	return lef_output(skb);
+}
+
+int			lef_forward(struct sk_buff *skb)
+{
+	struct iphdr *iph;	/* Our header */
+
+	if (skb->pkt_type != PACKET_HOST)
+		goto drop;
+
+	skb->ip_summed = CHECKSUM_NONE;
+	iph = skb->nh.iph;
+
+	/*
+	 *	According to the RFC, we must first decrease the TTL field. If
+	 *	that reaches zero, we must reply an ICMP control message telling
+	 *	that the packet's lifetime expired.
+	 */
+	if (iph->ttl <= 1)
+                goto too_many_hops;
+
+	/* We are about to mangle packet. Copy it! */
+	if (skb_cow(skb, LL_RESERVED_SPACE(skb->lef.dev)))
+		goto drop;
+
+	/* Decrease ttl after skb cow done */
+	ip_decrease_ttl(iph);
+
+	skb->priority = rt_tos2priority(iph->tos);
+
+	return NF_HOOK(PF_INET, NF_IP_FORWARD, skb, skb->dev, skb->lef.dev,
+		       lef_forward_finish);
+
+too_many_hops:
+        /* Tell the sender its packet died... */
+        IP_INC_STATS_BH(IPSTATS_MIB_INHDRERRORS);
+        icmp_send(skb, ICMP_TIME_EXCEEDED, ICMP_EXC_TTL, 0);
+drop:
+	kfree_skb(skb);
+	return NET_RX_DROP;
+}
--- linux-2.6.18.orig/net/ipv4/ip_input.c	2006-09-20 05:42:06.000000000 +0200
+++ linux-2.6.18/net/ipv4/ip_input.c	2006-11-14 19:13:18.000000000 +0100
@@ -146,6 +146,10 @@
 #include <linux/mroute.h>
 #include <linux/netlink.h>
 
+#ifdef CONFIG_IP_LEF
+#include <net/lef.h>
+#endif
+
 /*
  *	SNMP management statistics
  */
@@ -331,14 +335,22 @@
 static inline int ip_rcv_finish(struct sk_buff *skb)
 {
 	struct iphdr *iph = skb->nh.iph;
+	int ip_has_options = iph->ihl > 5;
 
 	/*
 	 *	Initialise the virtual path cache for the packet. It describes
 	 *	how the packet travels inside Linux networking.
+	 *	Only packets without IP options can be handled by LEF, so
+	 *	give the function this information.
 	 */ 
 	if (skb->dst == NULL) {
+#ifdef CONFIG_IP_LEF
+		int err = ip_route_input_lef(skb, iph->daddr, iph->saddr, iph->tos,
+					 skb->dev, !ip_has_options);
+#else
 		int err = ip_route_input(skb, iph->daddr, iph->saddr, iph->tos,
 					 skb->dev);
+#endif
 		if (unlikely(err)) {
 			if (err == -EHOSTUNREACH)
 				IP_INC_STATS_BH(IPSTATS_MIB_INADDRERRORS);
@@ -347,6 +359,9 @@
 	}
 
 #ifdef CONFIG_NET_CLS_ROUTE
+#ifdef CONFIG_IP_LEF
+	if (skb->dst) {
+#endif
 	if (unlikely(skb->dst->tclassid)) {
 		struct ip_rt_acct *st = ip_rt_acct + 256*smp_processor_id();
 		u32 idx = skb->dst->tclassid;
@@ -355,11 +370,19 @@
 		st[(idx>>16)&0xFF].i_packets++;
 		st[(idx>>16)&0xFF].i_bytes+=skb->len;
 	}
+#ifdef CONFIG_IP_LEF
+	}
+#endif
 #endif
 
-	if (iph->ihl > 5 && ip_rcv_options(skb))
+	if (ip_has_options && ip_rcv_options(skb))
 		goto drop;
 
+#ifdef CONFIG_IP_LEF
+	if (!skb->dst)
+		return lef_forward(skb);
+	else
+#endif
 	return dst_input(skb);
 
 drop:
--- linux-2.6.19.1.orig/net/ipv4/fib_semantics.c	2006-12-11 20:32:53.000000000 +0100
+++ linux-2.6.19.1/net/ipv4/fib_semantics.c	2007-02-05 12:08:23.000000000 +0100
@@ -153,6 +153,11 @@
 		if (nh->nh_dev)
 			dev_put(nh->nh_dev);
 		nh->nh_dev = NULL;
+#ifdef CONFIG_IP_LEF
+		if (nh->neighbour)
+			neigh_release(nh->neighbour);
+		nh->neighbour = NULL;
+#endif
 	} endfor_nexthops(fi);
 	fib_info_cnt--;
 	kfree(fi);
@@ -845,13 +850,31 @@
 	return ERR_PTR(err);
 }
 
+#ifdef CONFIG_IP_LEF
+/* dst_hash - for hashing a flowi */
+static inline unsigned char __ip4_hash(const unsigned char *ip)
+{
+	return ip[0] + ip[1] + ip[2] + ip[3];
+}
+
+static inline unsigned char __flowi_hash(const struct flowi *flp)
+{
+	return __ip4_hash((unsigned char*)&flp->fl4_dst) +
+		jiffies;
+}
+#endif
+
 /* Note! fib_semantic_match intentionally uses  RCU list functions. */
 int fib_semantic_match(struct list_head *head, const struct flowi *flp,
 		       struct fib_result *res, __be32 zone, __be32 mask,
 			int prefixlen)
 {
 	struct fib_alias *fa;
-	int nh_sel = 0;
+	int nh_sel;
+#ifdef CONFIG_IP_LEF
+	const struct fib_nh *_nh;
+	unsigned _fib_nhs;
+#endif
 
 	list_for_each_entry_rcu(fa, head, fa_list) {
 		int err;
@@ -860,8 +883,10 @@
 		    fa->fa_tos != flp->fl4_tos)
 			continue;
 
+#ifndef CONFIG_IP_LEF
 		if (fa->fa_scope < flp->fl4_scope)
 			continue;
+#endif
 
 		fa->fa_state |= FA_S_ACCESSED;
 
@@ -872,12 +897,51 @@
 			if (fi->fib_flags & RTNH_F_DEAD)
 				continue;
 
+#ifdef CONFIG_IP_LEF
+			_fib_nhs = fi->fib_nhs;
+#endif
+
+#ifndef CONFIG_IP_LEF
 			switch (fa->fa_type) {
 			case RTN_UNICAST:
 			case RTN_LOCAL:
 			case RTN_BROADCAST:
 			case RTN_ANYCAST:
 			case RTN_MULTICAST:
+#endif
+#ifdef CONFIG_IP_LEF
+				{
+					int _nh_i;
+
+					if (likely(_fib_nhs == 1)) {
+						_nh = fi->fib_nh;
+						if (likely(!(_nh->nh_flags&RTNH_F_DEAD))) {
+							if (!flp->oif || flp->oif == _nh->nh_oif) {
+								nh_sel = 0;
+								goto out_fill_res;
+							}
+						}
+					} else {
+						nh_sel = ((unsigned)__flowi_hash(flp) % _fib_nhs);
+						for (_nh_i = 0; _nh_i < _fib_nhs; _nh_i++) {
+							_nh = fi->fib_nh + nh_sel;
+
+							if (likely(!(_nh->nh_flags&RTNH_F_DEAD))) {
+								if (!flp->oif || flp->oif == _nh->nh_oif)
+									break;
+							}
+							nh_sel = (nh_sel + 1) % _fib_nhs;
+						}
+					}
+#ifdef CONFIG_IP_ROUTE_MULTIPATH
+					if (_nh_i < _fib_nhs)
+						goto out_fill_res;
+#else
+					if (_nh_i < 1)
+						goto out_fill_res;
+#endif
+				}
+#else
 				for_nexthops(fi) {
 					if (nh->nh_flags&RTNH_F_DEAD)
 						continue;
@@ -895,12 +959,15 @@
 				}
 #endif
 				endfor_nexthops(fi);
+#endif
 				continue;
+#ifndef CONFIG_IP_LEF
 
 			default:
 				printk(KERN_DEBUG "impossible 102\n");
 				return -EINVAL;
 			};
+#endif
 		}
 		return err;
 	}
@@ -916,6 +983,9 @@
 	res->netmask = mask;
 	res->network = zone & inet_make_mask(prefixlen);
 #endif
+#ifdef CONFIG_IP_LEF
+	res->nh = (struct fib_nh*)_nh;
+#endif
 	atomic_inc(&res->fi->fib_clntref);
 	return 0;
 }
@@ -1045,6 +1115,9 @@
 		struct hlist_head *head = &fib_info_devhash[hash];
 		struct hlist_node *node;
 		struct fib_nh *nh;
+#ifdef CONFIG_IP_LEF
+		struct neighbour *neigh;
+#endif
 
 		hlist_for_each_entry(nh, node, head, nh_hash) {
 			struct fib_info *fi = nh->nh_parent;
@@ -1067,6 +1140,12 @@
 					nh->nh_power = 0;
 					spin_unlock_bh(&fib_multipath_lock);
 #endif
+#ifdef CONFIG_IP_LEF
+					if ((neigh = nh->neighbour)) {
+						nh->neighbour = NULL;
+						neigh_release(neigh);
+					}
+#endif
 					dead++;
 				}
 #ifdef CONFIG_IP_ROUTE_MULTIPATH
--- a/include/net/ip_fib.h	2006-12-18 09:27:06.000000000 +0100
+++ linux-2.6.19/include/net/ip_fib.h	2006-12-18 09:29:35.000000000 +0100
@@ -61,6 +61,9 @@
 #endif
 	int			nh_oif;
 	__be32			nh_gw;
+#ifdef CONFIG_IP_LEF
+	struct neighbour	*neighbour;
+#endif
 };
 
 /*
@@ -111,6 +114,7 @@
 #ifdef CONFIG_IP_MULTIPLE_TABLES
 	struct fib_rule	*r;
 #endif
+	struct fib_nh	*nh;
 };
 
 struct fib_result_nl {
@@ -130,7 +134,11 @@
 
 #ifdef CONFIG_IP_ROUTE_MULTIPATH
 
+#ifdef CONFIG_IP_LEF
+#define FIB_RES_NH(res)		(*((res).nh))
+#else
 #define FIB_RES_NH(res)		((res).fi->fib_nh[(res).nh_sel])
+#endif
 #define FIB_RES_RESET(res)	((res).nh_sel = 0)
 
 #else /* CONFIG_IP_ROUTE_MULTIPATH */
@@ -179,6 +187,8 @@
 #define _tb_lookup fn_trie_lookup
 #elif defined(CONFIG_IP_FIB_RADIX)
 #define _tb_lookup fn_radix_lookup
+#elif defined(CONFIG_IP_FIB_LEF)
+#define _tb_lookup fn_lef_lookup
 #endif
 
 extern int _tb_lookup(struct fib_table *, const struct flowi *, struct fib_result *);
--- linux-2.6.20.3/net/ipv4/fib_lef.c.orig	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.20.3/net/ipv4/fib_lef.c	2007-03-26 20:04:29.000000000 +0200
@@ -0,0 +1,970 @@
+/*
+ *   This program is free software; you can redistribute it and/or
+ *   modify it under the terms of the GNU General Public License
+ *   as published by the Free Software Foundation; either version
+ *   2 of the License, or (at your option) any later version.
+ *
+ *   A modified radix based FIB implemetation by krichy (LEF)
+ */
+
+#include <asm/uaccess.h>
+#include <asm/system.h>
+#include <asm/bitops.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/mm.h>
+#include <linux/string.h>
+#include <linux/socket.h>
+#include <linux/sockios.h>
+#include <linux/errno.h>
+#include <linux/in.h>
+#include <linux/inet.h>
+#include <linux/inetdevice.h>
+#include <linux/netdevice.h>
+#include <linux/if_arp.h>
+#include <linux/proc_fs.h>
+#include <linux/rcupdate.h>
+#include <linux/skbuff.h>
+#include <linux/netlink.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <net/ip.h>
+#include <net/protocol.h>
+#include <net/route.h>
+#include <net/tcp.h>
+#include <net/sock.h>
+#include <net/ip_fib.h>
+#include "fib_lookup.h"
+
+/*
+ * a modified radix tree implemetation
+ */
+
+
+/* many code is borrowed from fib_radix, please, forgive me :) */
+
+#define	HBIT		0x80000000	// high bit
+
+#define BPS		4		// Bits Per Subtree
+
+#if defined(LITTLE_ENDIAN)
+
+#elif defined(BIG_ENDIAN) /* defined(LITTLE_ENDIAN) */
+
+#endif /* defined(BIG_ENDIAN) */
+
+#ifndef	EX_KEY
+#define EX_KEY(k)	(((k) >> (32 - BPS)) & (~((~0) << BPS)))
+#endif
+
+static struct kmem_cache*	fn_alias_kmem __read_mostly;
+
+static void __alias_free_mem(struct rcu_head *head)
+{
+	struct fib_alias *fa = container_of(head, struct fib_alias, rcu);
+
+	BUG_ON(!fa->fa_info);
+	fib_release_info(fa->fa_info);
+
+	kmem_cache_free(fn_alias_kmem, fa);
+}
+
+static inline void alias_free_mem_rcu(struct fib_alias *fa)
+{
+	call_rcu(&fa->rcu, __alias_free_mem);
+}
+
+// forward declare radix_node
+struct radix_node;
+
+typedef struct lef_node {
+	struct lef_node		*child[1 << BPS];
+	struct lef_node		*parent;	// parent lef_node
+	struct lef_node		**pp;		// the pointer to us
+	struct radix_node	*rnode;		// the radix_node root
+	u8			key;
+	struct rcu_head		rcu;
+} lef_t;
+
+typedef struct radix_node {
+	struct list_head	falh;
+	struct radix_node	*l_child;	// left child  (0)
+	struct radix_node	*r_child;	// right child (1)
+	struct radix_node	*parent;	// parent
+	struct radix_node	**pp;		// parent's pointer to us
+	struct lef_node		*lparent;	// lef parent
+	struct rcu_head		rcu;
+} radix_t;
+
+// create a new lef node
+static inline lef_t		*new_lef_node(void)
+{
+	lef_t			*nl = kmalloc(sizeof(lef_t), GFP_KERNEL);
+
+	if (likely(nl)) {
+		memset(nl->child, 0, sizeof(nl->child));
+		nl->parent = NULL;
+		nl->pp = NULL;
+		nl->rnode = NULL;
+		nl->key = 0;
+		INIT_RCU_HEAD(&nl->rcu);
+	}
+
+	return nl;
+}
+
+// create a new node
+static inline radix_t		*new_radix_node(void)
+{
+	radix_t			*nn = kmalloc(sizeof(radix_t), GFP_KERNEL);
+	if (likely(nn)) {
+		nn->l_child = NULL;
+		nn->r_child = NULL;
+		nn->parent = NULL;
+		nn->pp = NULL;
+		nn->lparent = NULL;
+		INIT_LIST_HEAD(&nn->falh);
+		INIT_RCU_HEAD(&nn->rcu);
+	}
+	return nn;
+}
+
+// get a node and possibly create it
+static radix_t			*get_node(lef_t** p, u32 k, int klen)
+{
+	lef_t			*lp = NULL;	// lef parent
+	lef_t			*ln;		// lef node
+	radix_t			*rp;		// radix parent
+	radix_t			**rpp;		// radix parent's pointer to us
+	radix_t			*rn;		// radix node
+	u8			lkey = 0;
+
+	if (klen < 0 || klen > 32)
+		return NULL;
+
+	while( 1 ) {
+		ln = *p;
+
+		// we create the node if it does not exist
+		if (!ln) {
+			ln = new_lef_node();
+			if (unlikely(!ln))
+				return NULL;
+			ln->pp = p;
+			ln->key = lkey;
+
+			rcu_assign_pointer(ln->parent, lp);
+			rcu_assign_pointer(*p, ln);
+		}
+
+		if (klen < BPS)
+			break;
+
+		lkey = EX_KEY(k);
+		k <<= BPS;
+		klen -= BPS;
+
+		p = &ln->child[lkey];
+		lp = ln;
+	}
+
+	rp = NULL;
+	rpp = &ln->rnode;
+	while( 1 ) {
+		rn = *rpp;
+
+		if (!rn) {
+			rn = new_radix_node();
+			if (unlikely(!rn))
+				return NULL;
+			rn->pp = rpp;
+			rn->lparent = ln;
+
+			rcu_assign_pointer(rn->parent, rp);
+			rcu_assign_pointer(*rpp, rn);
+		}
+
+		if (klen == 0)
+			break;
+
+		if (k & HBIT)
+			rpp = &rn->r_child;
+		else
+			rpp = &rn->l_child;
+
+		rp = rn;
+		k <<= 1;
+		klen--;
+	}
+
+	return rn;
+}
+
+// insert a routing entry
+static int
+fn_lef_insert(struct fib_table* tb, struct fib_config *cfg)
+{
+	struct fib_alias	*fa, *new_fa;
+	struct fib_info		*fi;
+
+	int			plen = cfg->fc_dst_len;
+	u8			tos = cfg->fc_tos;
+	u32			key, mask;
+	int			err = 0;
+	radix_t*		n;
+
+	if (plen > 32)
+		return -EINVAL;
+
+	key = 0;
+	if (cfg->fc_dst)
+		key = ntohl(cfg->fc_dst);
+
+	mask = ntohl(inet_make_mask(plen));
+
+	if (key & ~mask)
+		return -EINVAL;
+
+	fi = fib_create_info(cfg);
+
+	if (IS_ERR(fi)) {
+		err = PTR_ERR(fi);
+		goto err;
+	}
+
+	n = get_node((lef_t**)tb->tb_data, key, plen);
+
+	if (unlikely(!n)) {
+		err = -ENOBUFS;
+		goto out;
+	}
+
+	fa = fib_find_alias(&n->falh, tos, fi->fib_priority);
+
+	/* Now fa, if non-NULL, points to the first fib alias
+	 * with the same keys [prefix,tos,priority], if such key already
+	 * exists or to the node before which we will insert new one.
+	 *
+	 * If fa is NULL, we will need to allocate a new one and
+	 * insert to the head of f.
+	 *
+	 * If f is NULL, no fib node matched the destination key
+	 * and we need to allocate a new one of those as well.
+	 */
+
+	if (fa && fa->fa_info->fib_priority == fi->fib_priority) {
+		struct fib_alias *fa_orig;
+
+		err = -EEXIST;
+		if (cfg->fc_nlflags & NLM_F_EXCL)
+			goto out;
+
+		if (cfg->fc_nlflags & NLM_F_REPLACE) {
+			struct fib_info *fi_drop;
+			u8 state;
+
+			err = -ENOBUFS;
+			new_fa = kmem_cache_alloc(fn_alias_kmem, GFP_KERNEL);
+			if (new_fa == NULL)
+				goto out;
+
+			fi_drop = fa->fa_info;
+			new_fa->fa_tos = fa->fa_tos;
+			new_fa->fa_info = fi;
+			new_fa->fa_type = cfg->fc_type;
+			new_fa->fa_scope = cfg->fc_scope;
+			state = fa->fa_state;
+			new_fa->fa_state &= ~FA_S_ACCESSED;
+
+			list_replace_rcu(&fa->fa_list, &new_fa->fa_list);
+			alias_free_mem_rcu(fa);
+
+			if (state & FA_S_ACCESSED)
+				rt_cache_flush(-1);
+
+			goto succeeded;
+		}
+
+		/* Error if we find a perfect match which
+		 * uses the same scope, type, and nexthop
+		 * information.
+		 */
+		fa_orig = fa;
+		list_for_each_entry(fa, fa_orig->fa_list.prev, fa_list) {
+			if (fa->fa_tos != tos)
+				break;
+			if (fa->fa_info->fib_priority != fi->fib_priority)
+				break;
+			if (fa->fa_type == cfg->fc_type &&
+			    fa->fa_scope == cfg->fc_scope &&
+			    fa->fa_info == fi) {
+				goto out;
+			}
+		}
+		if (!(cfg->fc_nlflags & NLM_F_APPEND))
+			fa = fa_orig;
+	}
+	err = -ENOENT;
+	if (!(cfg->fc_nlflags & NLM_F_CREATE))
+		goto out;
+
+	err = -ENOBUFS;
+	new_fa = kmem_cache_alloc(fn_alias_kmem, GFP_KERNEL);
+	if (new_fa == NULL)
+		goto out;
+
+	new_fa->fa_info = fi;
+	new_fa->fa_tos = tos;
+	new_fa->fa_type = cfg->fc_type;
+	new_fa->fa_scope = cfg->fc_scope;
+	new_fa->fa_state = 0;
+
+	list_add_tail_rcu(&new_fa->fa_list, (fa ? &fa->fa_list : &n->falh));
+
+	rt_cache_flush(-1);
+	rtmsg_fib(RTM_NEWROUTE, htonl(key), new_fa, plen, tb->tb_id, &cfg->fc_nlinfo);
+succeeded:
+	return 0;
+
+out:
+	fib_release_info(fi);
+err:
+	return err;
+}
+
+#ifdef CONFIG_IP_MULTIPLE_TABLES
+static
+#endif
+int
+fn_lef_lookup(struct fib_table *tb, const struct flowi *flp, struct fib_result *res)
+{
+	lef_t			*ln;		// current lef node
+	radix_t			*rn;		// current node
+	int			plen = 0;
+	u32			key = ntohl(flp->fl4_dst);
+	struct list_head	*fas[BPS+1];	// we collect all possible points here and start matching backwards
+	int			plens[BPS+1];
+#ifdef CONFIG_IP_ROUTE_MULTIPATH_CACHED
+	u32			mask = 0;	// mask is only needed when multipath caching is enabled
+						// read fib_semantic_match in fib_semantics.c
+	u32			masks[BPS+1];	// the mask for each possible node
+#endif
+	int			fap;
+	struct list_head	*fah;
+
+	rcu_read_lock();
+
+	ln = rcu_dereference(*((lef_t**)tb->tb_data));
+
+	// first we walk down as deep as much we can
+	while ( ln ) {
+		lef_t	*next = ln->child[EX_KEY(key)];
+		if (!next)
+			break;
+
+		ln = next;
+		key <<= BPS;
+#ifdef CONFIG_IP_ROUTE_MULTIPATH_CACHED
+		mask = ~((~mask) >> BPS);
+#endif
+		plen += BPS;
+	}
+
+	// then we start walking the tree upwards
+	while ( ln ) {
+		u32 okey = key;	// orig key
+		rn = ln->rnode;
+		fap = 0;
+
+		while ( rn ) {
+			fah = &rn->falh;
+
+			if (!list_empty(fah)) {
+#ifdef CONFIG_IP_ROUTE_MULTIPATH_CACHED
+				masks[fap] = mask;
+#endif
+				plens[fap] = plen;
+				fas[fap++] = fah;
+			}
+
+			if (key & HBIT)
+				rn = rcu_dereference(rn->r_child);
+			else
+				rn = rcu_dereference(rn->l_child);
+
+#ifdef CONFIG_IP_ROUTE_MULTIPATH_CACHED
+			mask >>= 1;
+			mask |= HBIT;
+#endif
+			plen++;
+			key <<= 1;
+		}
+
+		while( --fap >= 0 ) {
+#ifdef CONFIG_IP_ROUTE_MULTIPATH_CACHED
+			if (fib_semantic_match(fas[fap], flp, res, ntohl(flp->fl4_dst), masks[fap], plens[fap]) <= 0)
+#else
+			if (fib_semantic_match(fas[fap], flp, res, 0, 0, plens[fap]) <= 0)
+#endif
+			{
+				rcu_read_unlock();
+				return 0;
+			}
+		}
+
+		// restore key and step one up
+		key = (ln->key << (32 - BPS)) | (okey >> BPS);
+		ln = rcu_dereference(ln->parent);
+		plen -= BPS;
+#ifdef CONFIG_IP_ROUTE_MULTIPATH_CACHED
+		mask <<= BPS;
+#endif
+	}
+	rcu_read_unlock();
+
+	return -ESRCH;
+}
+
+static inline int	radix_node_has_refs(radix_t* n)
+{
+	return !list_empty(&n->falh) || n->l_child || n->r_child;
+}
+
+static inline int	lef_node_has_refs(const lef_t* l)
+{
+	int		i;
+
+	if (l->rnode)
+		return 1;
+	for (i=0; i<(1 << BPS); i++) {
+		if (l->child[i])
+			return 1;
+	}
+
+	return 0;
+}
+
+static void		__lef_delete_node(struct rcu_head *head)
+{
+	lef_t		*l = container_of(head, lef_t, rcu);
+
+	BUG_ON(lef_node_has_refs(l));
+
+	kfree(l);
+}
+
+static void		__radix_delete_node(struct rcu_head *head)
+{
+	radix_t*	n = container_of(head, radix_t, rcu);
+
+	BUG_ON(radix_node_has_refs(n));
+
+	kfree(n);
+}
+
+static inline void	lef_delete_node(lef_t *l)
+{
+	call_rcu(&l->rcu, __lef_delete_node);
+}
+
+static inline void	radix_delete_node(radix_t *s)
+{
+	call_rcu(&s->rcu, __radix_delete_node);
+}
+
+static void		lef_remove_node(lef_t *l)
+{
+	BUG_ON(!l);
+
+	rcu_assign_pointer(*(l->pp), NULL);
+
+	if (l->parent && !lef_node_has_refs(l->parent))
+		lef_remove_node(l->parent);
+
+	lef_delete_node(l);
+}
+
+static void		radix_remove_node(radix_t *n)
+{
+	BUG_ON(!n);
+
+	rcu_assign_pointer(*(n->pp), NULL);
+
+	if (n->parent && !radix_node_has_refs(n->parent))
+		radix_remove_node(n->parent);
+	if (!n->parent && n->lparent && !lef_node_has_refs(n->lparent))
+		lef_remove_node(n->lparent);
+
+	radix_delete_node(n);
+}
+
+static int
+fn_lef_delete(struct fib_table *tb, struct fib_config *cfg)
+{
+	// we do a lookup here, but only for a maximum depth
+	lef_t			*ln = *((lef_t**)tb->tb_data);
+	radix_t			*rn;
+	int			plen = cfg->fc_dst_len;
+	u32			key, mask;
+	struct list_head	*fa_head;
+	struct fib_alias	*fa, *fa_to_delete;
+
+	if (plen > 32)
+		return -EINVAL;
+
+	key = 0;
+	if (cfg->fc_dst)
+		key = ntohl(cfg->fc_dst);
+
+	mask = ntohl(inet_make_mask(plen));
+
+	if (key & ~mask)
+		return -EINVAL;
+
+	while ( ln && plen >= BPS ) {
+		ln=ln->child[EX_KEY(key)];
+		key <<= BPS;
+		plen -= BPS;
+	}
+
+	if (!ln)
+		return -ESRCH;
+
+	rn = ln->rnode;
+
+	while ( plen && rn ) {
+		if (key & HBIT)
+			rn = rn->r_child;
+		else
+			rn = rn->l_child;
+
+		key <<= 1;
+		plen--;
+	}
+
+	if (plen || !rn)
+		return -ESRCH;
+
+	fa_to_delete = NULL;
+	fa_head = &rn->falh;
+
+	list_for_each_entry(fa, fa_head, fa_list) {
+		struct fib_info *fi = fa->fa_info;
+
+		if (fa->fa_tos != cfg->fc_tos)
+			break;
+
+		if ((!cfg->fc_type ||
+		     fa->fa_type == cfg->fc_type) &&
+		    (cfg->fc_scope == RT_SCOPE_NOWHERE ||
+		     fa->fa_scope == cfg->fc_scope) &&
+		    (!cfg->fc_protocol ||
+		     fi->fib_protocol == cfg->fc_protocol) &&
+		    fib_nh_match(cfg, fi) == 0) {
+			fa_to_delete = fa;
+			break;
+		}
+	}
+
+	if (!fa_to_delete)
+		return -ESRCH;
+
+	fa = fa_to_delete;
+	rtmsg_fib(RTM_DELROUTE, htonl(key), fa, plen, tb->tb_id, &cfg->fc_nlinfo);
+
+	list_del_rcu(&fa->fa_list);
+
+	// now the entry is removed, we must find the top-most node which can be removed
+	if (!radix_node_has_refs(rn))
+		radix_remove_node(rn);
+
+	if (fa->fa_state & FA_S_ACCESSED)
+		rt_cache_flush(-1);
+
+	alias_free_mem_rcu(fa);
+
+	return 0;
+}
+
+static int last_dflt = -1;
+
+static void
+fn_lef_select_default(struct fib_table *tb, const struct flowi *flp, struct fib_result *res)
+{
+	lef_t		*ln;
+	radix_t		*rn;
+	int order, last_idx;
+	struct fib_info *fi = NULL;
+	struct fib_info *last_resort;
+	struct fib_alias *fa = NULL;
+	struct list_head *fa_head;
+
+	last_idx = -1;
+	last_resort = NULL;
+	order = -1;
+
+	rcu_read_lock();
+
+	ln = rcu_dereference(*((lef_t**)tb->tb_data));
+	if (!ln)
+		goto out;
+
+	rn = rcu_dereference(ln->rnode);
+	if (!rn)
+		goto out;
+
+	fa_head = &rn->falh;
+
+	if (!fa_head)
+		goto out;
+
+	if (list_empty(fa_head))
+		goto out;
+
+	list_for_each_entry_rcu(fa, fa_head, fa_list) {
+		struct fib_info *next_fi = fa->fa_info;
+
+		if (fa->fa_scope != res->scope ||
+		    fa->fa_type != RTN_UNICAST)
+			continue;
+
+		if (next_fi->fib_priority > res->fi->fib_priority)
+			break;
+		if (!next_fi->fib_nh[0].nh_gw ||
+		    next_fi->fib_nh[0].nh_scope != RT_SCOPE_LINK)
+			continue;
+		fa->fa_state |= FA_S_ACCESSED;
+
+		if (fi == NULL) {
+			if (next_fi != res->fi)
+				break;
+		} else if (!fib_detect_death(fi, order, &last_resort,
+					     &last_idx, &last_dflt)) {
+			if (res->fi)
+				fib_info_put(res->fi);
+			res->fi = fi;
+			atomic_inc(&fi->fib_clntref);
+			last_dflt = order;
+			goto out;
+		}
+		fi = next_fi;
+		order++;
+	}
+	if (order <= 0 || fi == NULL) {
+		last_dflt = -1;
+		goto out;
+	}
+
+	if (!fib_detect_death(fi, order, &last_resort, &last_idx, &last_dflt)) {
+		if (res->fi)
+			fib_info_put(res->fi);
+		res->fi = fi;
+		atomic_inc(&fi->fib_clntref);
+		last_dflt = order;
+		goto out;
+	}
+	if (last_idx >= 0) {
+		if (res->fi)
+			fib_info_put(res->fi);
+		res->fi = last_resort;
+		if (last_resort)
+			atomic_inc(&last_resort->fib_clntref);
+	}
+	last_dflt = last_idx;
+ out:;
+	rcu_read_unlock();
+}
+
+#define BIT(i)  (HBIT >> (i-1))
+#define TB(v,i)	((v) & BIT(i))
+
+static int fn_lef_dump(struct fib_table *tb, struct sk_buff *skb, struct netlink_callback *cb)
+{
+	u32			key = cb->args[2];	// represents the actual key
+	u32			plen = cb->args[3];	// represents the actual key length
+	int			i;
+	struct list_head	*fah;
+	radix_t			*child;
+
+	radix_t			*rn;
+	radix_t			*nn;
+	lef_t			*ln;
+	lef_t			*lp;
+	u32			lef_key;
+	int			lpos = 0;
+
+	// pre-order tree traversal
+	rcu_read_lock();
+
+	// first of all we look for our node
+	ln = rcu_dereference(*((lef_t**)tb->tb_data));
+
+	i = 0;
+	lef_key = key;
+	while ( ln && (i+BPS <= plen) ) {
+		lef_t	*next = ln->child[EX_KEY(lef_key)];
+		if (!next)
+			break;
+
+		ln = next;
+		i += BPS;
+		lef_key <<= BPS;
+		lpos += BPS;
+	}
+
+	rn = ln ? ln->rnode : NULL;
+
+	if ( i+BPS <= plen || !rn ) { // unfortunately our node has disappeared
+		plen = i;
+	} else {
+		while( i < plen ) {
+			if (TB(key,i+1))
+				nn = rcu_dereference(rn->r_child);
+			else
+				nn = rcu_dereference(rn->l_child);
+			if (!nn)
+				break;
+			rn = nn;
+			i++;
+		}
+
+		plen = i;
+	}
+
+	key &= ntohl(inet_make_mask(plen));
+
+	// now we must continue pre-order traversal from n
+	while( ln ) {
+
+		while(rn) {
+			fah = &rn->falh;
+
+			if (!list_empty(fah)) {
+				int			fai = cb->args[4];
+				struct fib_alias	*fa;
+				u32			xkey = htonl(key);
+
+				i = 0;
+
+				list_for_each_entry_rcu(fa, fah, fa_list) {
+					if (i < fai) {
+						i++;
+						continue;
+					}
+
+					BUG_ON(!fa->fa_info);
+
+					if (fib_dump_info(skb, NETLINK_CB(cb->skb).pid,
+							  cb->nlh->nlmsg_seq,
+							  RTM_NEWROUTE,
+							  tb->tb_id,
+							  fa->fa_type,
+							  fa->fa_scope,
+							  xkey,
+							  plen,
+							  fa->fa_tos,
+							  fa->fa_info, 0) < 0) {
+
+						rcu_read_unlock();
+
+						cb->args[2] = key;
+						cb->args[3] = plen;
+						cb->args[4] = i;
+
+						return -1; // to indicate there is more data
+					}
+					i++;
+				}
+			}
+
+			// now must find next node to dump
+			cb->args[4] = 0;
+
+			if ((child = rcu_dereference(rn->l_child))) {
+				rn = child;
+				plen++;
+				WARN_ON(TB(key, plen));
+			} else if ((child = rcu_dereference(rn->r_child))) {
+				rn = child;
+				plen++;
+				WARN_ON(TB(key, plen));
+				key |= BIT(plen);	// set the last bit to 1
+			} else { // we must step upwards
+				radix_t*	p;
+				radix_t*	pr;
+
+				while((p = rcu_dereference(rn->parent))) {
+					pr = rcu_dereference(p->r_child);
+
+					if (pr != NULL && pr != rn)
+						break;
+
+					rn = p;
+					key &= ~BIT(plen); // set current bit to zero
+					plen--;
+				}
+
+				if (!p) {
+					break;
+				}
+
+				WARN_ON(TB(key, plen));	// it must be 0 now
+
+				rn = pr;
+				key |= BIT(plen);
+			}
+		}
+
+		WARN_ON(lpos != plen);
+
+		for (i = 0; i<(1 << BPS); i++) {
+			lef_t	*ch = rcu_dereference(ln->child[i]);
+
+			if (ch) {
+				// step down in lef tree
+				lpos += BPS;
+				plen += BPS;
+				key |= i << (32 - lpos);
+				ln = ch;
+				break;
+			}
+		}
+
+		if (i == (1 << BPS)) { // no child was found
+			while((lp = rcu_dereference(ln->parent))) {
+				key &= ~(((~0U) << (32-BPS)) >> (lpos - BPS));
+
+				WARN_ON(lp->child[ln->key] != ln);
+
+				for(i=ln->key + 1; i<(1 << BPS); i++) {
+					lef_t *ch = rcu_dereference(lp->child[i]);
+					if (ch) {
+						key |= i << (32 - lpos);
+						ln = ch;
+						break;
+					}
+				}
+				if (i < (1 << BPS))
+					break;
+
+				ln = lp;
+				lpos -= BPS;
+				plen -= BPS;
+			}
+			if (!lp)
+				break;
+		}
+
+		rn = ln->rnode;
+	}
+
+	rcu_read_unlock();
+
+	WARN_ON(plen != 0); // we should leave only if plen == 0
+
+	return skb->len;
+}
+
+static int	radix_flush_recursive(radix_t* n)
+{
+	struct fib_alias	*fa, *fa_node;
+	int			found = 0;
+
+	if (!n)
+		return 0;
+
+	found += radix_flush_recursive(n->l_child);
+	found += radix_flush_recursive(n->r_child);
+
+	list_for_each_entry_safe(fa, fa_node, &n->falh, fa_list) {
+		struct fib_info *fi = fa->fa_info;
+
+		if (fi && (fi->fib_flags & RTNH_F_DEAD)) {
+			list_del_rcu(&fa->fa_list);
+			alias_free_mem_rcu(fa);
+			found++;
+		}
+	}
+
+	if (!radix_node_has_refs(n)) { // dont delete parents, recursion will do that
+		rcu_assign_pointer(n->parent, NULL);
+		radix_remove_node(n);
+	}
+
+	return found;
+}
+
+static int	lef_flush_recursive(lef_t* l)
+{
+	int			i;
+	int			found = 0;
+
+	for (i=0; i<(1 << BPS); i++) {
+		if (l->child[i])
+			found += lef_flush_recursive(l->child[i]);
+	}
+	if (l->rnode)
+		found += radix_flush_recursive(l->rnode);
+
+	if (!lef_node_has_refs(l)) {
+		rcu_assign_pointer(l->parent, NULL); // skip recursion upwards
+		lef_remove_node(l);
+	}
+
+	return found;
+}
+
+static int	fn_lef_flush(struct fib_table *tb)
+{
+	lef_t*			l = *((lef_t**)tb->tb_data);
+	int			found = 0;
+
+	if (l)
+		found += lef_flush_recursive(l);
+
+	return found;
+}
+
+#ifdef CONFIG_IP_MULTIPLE_TABLES
+struct fib_table * fib_hash_init(u32 id)
+#else
+struct fib_table * __init fib_hash_init(u32 id)
+#endif
+{
+	struct fib_table *tb;
+
+	if (fn_alias_kmem == NULL)
+		fn_alias_kmem = kmem_cache_create("ip_fib_alias",
+						  sizeof(struct fib_alias),
+						  0, SLAB_HWCACHE_ALIGN,
+						  NULL, NULL);
+
+	tb = kmalloc(sizeof(struct fib_table) + sizeof(radix_t*),
+		     GFP_KERNEL);
+	if (tb == NULL)
+		return NULL;
+
+	tb->tb_id = id;
+	tb->tb_lookup = fn_lef_lookup;
+	tb->tb_insert = fn_lef_insert;
+	tb->tb_delete = fn_lef_delete;
+	tb->tb_flush = fn_lef_flush;
+	tb->tb_select_default = fn_lef_select_default;
+	tb->tb_dump = fn_lef_dump;
+	memset(tb->tb_data, 0, sizeof(radix_t*));
+
+	printk(KERN_INFO "IPv4 FIB: Using LEF for table %u\n", id);
+
+	return tb;
+}
+
+int __init fib_proc_init(void)
+{
+	return 0;
+}
+
+void __init fib_proc_exit(void)
+{
+}
+
