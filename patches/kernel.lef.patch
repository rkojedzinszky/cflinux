commit 3ae965bb9da3cf570f2f550d61f5da49f34254aa
Author: Richard Kojedzinszky <krichy@cflinux.hu>
Date:   Sat Feb 2 23:19:18 2008 +0100

    Applied a770e63fd0..67acd9283a

diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h
index ed2c458..b948059 100644
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -29,6 +29,10 @@
 #include <linux/dmaengine.h>
 #include <linux/hrtimer.h>
 
+#ifdef CONFIG_IP_LEF
+#include <net/lef_struct.h>
+#endif
+
 #define HAVE_ALLOC_SKB		/* For the drivers to know */
 #define HAVE_ALIGNABLE_SKB	/* Ditto 8)		   */
 
@@ -258,6 +262,9 @@ struct sk_buff {
 
 	struct  dst_entry	*dst;
 	struct	sec_path	*sp;
+#ifdef CONFIG_IP_LEF
+	struct  lef		lef;
+#endif
 
 	/*
 	 * This is the control buffer. It is free to use for every
diff --git a/include/net/arp.h b/include/net/arp.h
index f026645..92e1e8b 100644
--- a/include/net/arp.h
+++ b/include/net/arp.h
@@ -16,6 +16,9 @@ extern void     arp_send(int type, int ptype, __be32 dest_ip,
 			 struct net_device *dev, __be32 src_ip,
 			 unsigned char *dest_hw, unsigned char *src_hw, unsigned char *th);
 extern int	arp_bind_neighbour(struct dst_entry *dst);
+#ifdef CONFIG_IP_LEF
+extern int	arp_bind_neighbour_lef(struct lef *lef, __be32 nexthop);
+#endif
 extern int	arp_mc_map(__be32 addr, u8 *haddr, struct net_device *dev, int dir);
 extern void	arp_ifdown(struct net_device *dev);
 
diff --git a/include/net/ip_fib.h b/include/net/ip_fib.h
index 8cadc77..d47161c 100644
--- a/include/net/ip_fib.h
+++ b/include/net/ip_fib.h
@@ -60,6 +60,9 @@ struct fib_nh {
 #endif
 	int			nh_oif;
 	__be32			nh_gw;
+#ifdef CONFIG_IP_LEF
+	struct neighbour	*neighbour;
+#endif
 };
 
 /*
@@ -103,6 +106,7 @@ struct fib_result {
 #ifdef CONFIG_IP_MULTIPLE_TABLES
 	struct fib_rule	*r;
 #endif
+	struct fib_nh	*nh;
 };
 
 struct fib_result_nl {
@@ -122,7 +126,11 @@ struct fib_result_nl {
 
 #ifdef CONFIG_IP_ROUTE_MULTIPATH
 
+#ifdef CONFIG_IP_LEF
+#define FIB_RES_NH(res)		(*((res).nh))
+#else
 #define FIB_RES_NH(res)		((res).fi->fib_nh[(res).nh_sel])
+#endif
 #define FIB_RES_RESET(res)	((res).nh_sel = 0)
 
 #else /* CONFIG_IP_ROUTE_MULTIPATH */
@@ -155,14 +163,23 @@ struct fib_table {
 
 #ifndef CONFIG_IP_MULTIPLE_TABLES
 
-extern struct fib_table *ip_fib_local_table;
 extern struct fib_table *ip_fib_main_table;
 
+#ifdef CONFIG_IP_FIB_HASH
+#define _tb_lookup fn_hash_lookup
+#endif
+#ifdef CONFIG_IP_FIB_TRIE
+#define _tb_lookup fn_trie_lookup
+#endif
+#ifdef CONFIG_IP_FIB_LEF
+#define _tb_lookup fn_lef_lookup
+#endif
+
+extern int _tb_lookup(struct fib_table *, const struct flowi *, struct fib_result *);
+
 static inline struct fib_table *fib_get_table(u32 id)
 {
-	if (id != RT_TABLE_LOCAL)
-		return ip_fib_main_table;
-	return ip_fib_local_table;
+	return ip_fib_main_table;
 }
 
 static inline struct fib_table *fib_new_table(u32 id)
@@ -172,8 +189,7 @@ static inline struct fib_table *fib_new_table(u32 id)
 
 static inline int fib_lookup(const struct flowi *flp, struct fib_result *res)
 {
-	if (ip_fib_local_table->tb_lookup(ip_fib_local_table, flp, res) &&
-	    ip_fib_main_table->tb_lookup(ip_fib_main_table, flp, res))
+	if (_tb_lookup(ip_fib_main_table, flp, res))
 		return -ENETUNREACH;
 	return 0;
 }
diff --git a/include/net/lef.h b/include/net/lef.h
new file mode 100644
index 0000000..2d03574
--- /dev/null
+++ b/include/net/lef.h
@@ -0,0 +1,63 @@
+/*
+ * Linux express forwarding code
+ *
+ * Mainly developed by krichy < krichy at cflinux dot hu >
+ *
+ * Currently it is under development, so do not expect much from it,
+ * or not anything else than a kernel panic. :)
+ *
+ * The code is subject to GPLv2 or any later one.
+ */
+
+#ifndef _NET_LEF_H
+#define _NET_LEF_H
+
+#include <asm/types.h>
+#include <asm/processor.h>
+#include <net/neighbour.h>
+#include <linux/netdevice.h>
+#include <net/neighbour.h>
+#include <net/lef_struct.h>
+
+// some trivial lef-related functions
+
+/* lef_init
+ * is called when initialising a lef structure
+ * it just zeros all elements of it
+ * @l: struct lef
+ */
+static inline void		lef_init(struct lef* l)
+{
+	memset(l, 0, sizeof(*l));
+}
+
+/* lef_init_copy
+ * inits a lef from another one (actually copying old contents
+ * and allocating references
+ * @l: new lef
+ * @o: old lef
+ */
+static inline void		lef_init_copy(struct lef* l, const struct lef* o)
+{
+	if ((l->dev = o->dev))
+		dev_hold(l->dev);
+	l->mtu = o->mtu;
+	if ((l->neighbour = o->neighbour))
+		neigh_hold(l->neighbour);
+}
+
+/* lef_destroy
+ * destroys (frees) elements of a lef
+ * @l: struct lef
+ */
+static inline void		lef_destroy(struct lef* l)
+{
+	if (likely(l->neighbour))
+		neigh_release(l->neighbour);
+	if (likely(l->dev))
+		dev_put(l->dev);
+}
+
+extern int			lef_forward(struct sk_buff *);
+
+#endif /* _NET_LEF_H */
diff --git a/include/net/lef_struct.h b/include/net/lef_struct.h
new file mode 100644
index 0000000..5edce59
--- /dev/null
+++ b/include/net/lef_struct.h
@@ -0,0 +1,29 @@
+/*
+ * Linux express forwarding code
+ *
+ * Mainly developed by krichy < krichy at cflinux dot hu >
+ *
+ * Currently it is under development, so do not expect much from it,
+ * or not anything else than a kernel panic. :)
+ *
+ * The code is subject to GPLv2 or any later one.
+ */
+
+#ifndef _NET_LEF_STRUCT_H
+#define _NET_LEF_STRUCT_H
+
+// forward declarations
+struct net_device;
+struct neighbour;
+
+// our express forwarding structure
+struct lef {
+	int			flags;		// flags
+	struct net_device	*dev;		// our device
+	__u32			mtu;		// our mtu
+	struct neighbour	*neighbour;	// our neigbour
+};
+
+#define	LEF_NEED		1		// we should use lef
+
+#endif /* _NET_LEF_STRUCT_H */
diff --git a/net/core/neighbour.c b/net/core/neighbour.c
index f7de8f2..1c2b0e5 100644
--- a/net/core/neighbour.c
+++ b/net/core/neighbour.c
@@ -35,6 +35,10 @@
 #include <linux/string.h>
 #include <linux/log2.h>
 
+#ifdef CONFIG_IP_LEF
+#include <net/lef.h>
+#endif
+
 #define NEIGH_DEBUG 1
 
 #define NEIGH_PRINTK(x...) printk(x)
@@ -1145,7 +1149,11 @@ int neigh_resolve_output(struct sk_buff *skb)
 	struct neighbour *neigh;
 	int rc = 0;
 
+#ifdef CONFIG_IP_LEF
+	if ((!dst || !(neigh = dst->neighbour)) && !(neigh = skb->lef.neighbour))
+#else
 	if (!dst || !(neigh = dst->neighbour))
+#endif
 		goto discard;
 
 	__skb_pull(skb, skb_network_offset(skb));
@@ -1153,7 +1161,11 @@ int neigh_resolve_output(struct sk_buff *skb)
 	if (!neigh_event_send(neigh, skb)) {
 		int err;
 		struct net_device *dev = neigh->dev;
+#ifdef CONFIG_IP_LEF
+		if (dst && dev->hard_header_cache && !dst->hh) {
+#else
 		if (dev->hard_header_cache && !dst->hh) {
+#endif
 			write_lock_bh(&neigh->lock);
 			if (!dst->hh)
 				neigh_hh_init(neigh, dst, dst->ops->protocol);
@@ -1188,8 +1200,17 @@ int neigh_connected_output(struct sk_buff *skb)
 {
 	int err;
 	struct dst_entry *dst = skb->dst;
-	struct neighbour *neigh = dst->neighbour;
-	struct net_device *dev = neigh->dev;
+	struct neighbour *neigh;
+	struct net_device *dev;
+
+#ifdef CONFIG_IP_LEF
+	if (!dst)
+		neigh = skb->lef.neighbour;
+	else
+#endif
+		neigh = dst->neighbour;
+
+	dev = neigh->dev;
 
 	__skb_pull(skb, skb_network_offset(skb));
 
diff --git a/net/core/skbuff.c b/net/core/skbuff.c
index 35021eb..ed22cc2 100644
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -66,6 +66,10 @@
 #include <asm/uaccess.h>
 #include <asm/system.h>
 
+#ifdef CONFIG_IP_LEF
+#include <net/lef.h>
+#endif
+
 #include "kmap_skb.h"
 
 static struct kmem_cache *skbuff_head_cache __read_mostly;
@@ -322,6 +326,9 @@ void __kfree_skb(struct sk_buff *skb)
 #ifdef CONFIG_XFRM
 	secpath_put(skb->sp);
 #endif
+#ifdef CONFIG_IP_LEF
+	lef_destroy(&skb->lef);
+#endif
 	if (skb->destructor) {
 		WARN_ON(in_irq());
 		skb->destructor(skb);
@@ -408,6 +415,9 @@ struct sk_buff *skb_clone(struct sk_buff *skb, gfp_t gfp_mask)
 #ifdef CONFIG_INET
 	secpath_get(skb->sp);
 #endif
+#ifdef CONFIG_IP_LEF
+	lef_init_copy(&n->lef, &skb->lef);
+#endif
 	memcpy(n->cb, skb->cb, sizeof(skb->cb));
 	C(len);
 	C(data_len);
@@ -481,6 +491,9 @@ static void copy_skb_header(struct sk_buff *new, const struct sk_buff *old)
 	new->network_header   += offset;
 	new->mac_header	      += offset;
 #endif
+#ifdef CONFIG_IP_LEF
+	lef_init_copy(&new->lef, &old->lef);
+#endif
 	memcpy(new->cb, old->cb, sizeof(old->cb));
 	new->local_df	= old->local_df;
 	new->fclone	= SKB_FCLONE_UNAVAILABLE;
@@ -1946,6 +1959,9 @@ struct sk_buff *skb_segment(struct sk_buff *skb, int features)
 		nskb->priority = skb->priority;
 		nskb->protocol = skb->protocol;
 		nskb->dst = dst_clone(skb->dst);
+#ifdef CONFIG_IP_LEF
+		lef_init_copy(&nskb->lef, &skb->lef);
+#endif
 		memcpy(nskb->cb, skb->cb, sizeof(skb->cb));
 		nskb->pkt_type = skb->pkt_type;
 		nskb->mac_len = skb->mac_len;
diff --git a/net/ipv4/Kconfig b/net/ipv4/Kconfig
index fb79097..6e0c02c 100644
--- a/net/ipv4/Kconfig
+++ b/net/ipv4/Kconfig
@@ -51,6 +51,12 @@ config IP_ADVANCED_ROUTER
 
 	  If unsure, say N here.
 
+config IP_LEF
+	bool "IP: Linux express forwarding"
+	depends on IP_ADVANCED_ROUTER
+	---help---
+	You should not turn this on
+
 choice 
 	prompt "Choose IP: FIB lookup algorithm (choose FIB_HASH if unsure)"
 	depends on IP_ADVANCED_ROUTER
@@ -80,6 +86,11 @@ config IP_FIB_TRIE
  	Stefan Nilsson and Matti Tikkanen. Algorithmica, 33(1):19-33, 2002.
  	http://www.nada.kth.se/~snilsson/public/papers/dyntrie2/
        
+config IP_FIB_LEF
+	bool "FIB_LEF"
+	---help---
+	An improved radix based IPv4 lookup algorithm. This needs much testing.
+
 endchoice
 
 config IP_FIB_HASH
diff --git a/net/ipv4/Makefile b/net/ipv4/Makefile
index fbf1674..5dd60d7 100644
--- a/net/ipv4/Makefile
+++ b/net/ipv4/Makefile
@@ -14,6 +14,7 @@ obj-y     := route.o inetpeer.o protocol.o \
 
 obj-$(CONFIG_IP_FIB_HASH) += fib_hash.o
 obj-$(CONFIG_IP_FIB_TRIE) += fib_trie.o
+obj-$(CONFIG_IP_FIB_LEF) += fib_lef.o
 obj-$(CONFIG_PROC_FS) += proc.o
 obj-$(CONFIG_IP_MULTIPLE_TABLES) += fib_rules.o
 obj-$(CONFIG_IP_MROUTE) += ipmr.o
@@ -47,6 +48,7 @@ obj-$(CONFIG_TCP_CONG_LP) += tcp_lp.o
 obj-$(CONFIG_TCP_CONG_YEAH) += tcp_yeah.o
 obj-$(CONFIG_TCP_CONG_ILLINOIS) += tcp_illinois.o
 obj-$(CONFIG_NETLABEL) += cipso_ipv4.o
+obj-$(CONFIG_IP_LEF) += lef.o
 
 obj-$(CONFIG_XFRM) += xfrm4_policy.o xfrm4_state.o xfrm4_input.o \
 		      xfrm4_output.o
diff --git a/net/ipv4/arp.c b/net/ipv4/arp.c
index 652da8e..b36dde7 100644
--- a/net/ipv4/arp.c
+++ b/net/ipv4/arp.c
@@ -122,6 +122,10 @@ struct neigh_table *clip_tbl_hook;
 
 #include <linux/netfilter_arp.h>
 
+#ifdef CONFIG_IP_LEF
+#include <net/lef.h>
+#endif
+
 /*
  *	Interface to generic neighbour cache.
  */
@@ -521,6 +525,30 @@ int arp_bind_neighbour(struct dst_entry *dst)
 	return 0;
 }
 
+#ifdef CONFIG_IP_LEF
+int arp_bind_neighbour_lef(struct lef *lef, __be32 nexthop)
+{
+	struct net_device *dev = lef->dev;
+	struct neighbour *n = lef->neighbour;
+
+	if (dev == NULL)
+		return -EINVAL;
+	if (n == NULL) {
+		if (dev->flags&(IFF_LOOPBACK|IFF_POINTOPOINT))
+			nexthop = 0;
+		n = __neigh_lookup_errno(
+#if defined(CONFIG_ATM_CLIP) || defined(CONFIG_ATM_CLIP_MODULE)
+		    dev->type == ARPHRD_ATM ? clip_tbl_hook :
+#endif
+		    &arp_tbl, &nexthop, dev);
+		if (IS_ERR(n))
+			return PTR_ERR(n);
+		lef->neighbour = n;
+	}
+	return 0;
+}
+#endif
+
 /*
  * Check if we can use proxy ARP for this path
  */
diff --git a/net/ipv4/fib_frontend.c b/net/ipv4/fib_frontend.c
index eff6bce..ced36cd 100644
--- a/net/ipv4/fib_frontend.c
+++ b/net/ipv4/fib_frontend.c
@@ -51,7 +51,6 @@
 
 #ifndef CONFIG_IP_MULTIPLE_TABLES
 
-struct fib_table *ip_fib_local_table;
 struct fib_table *ip_fib_main_table;
 
 #define FIB_TABLE_HASHSZ 1
@@ -131,8 +130,12 @@ struct net_device * ip_dev_find(__be32 addr)
 	res.r = NULL;
 #endif
 
+#ifdef CONFIG_IP_MULTIPLE_TABLES
 	if (!ip_fib_local_table ||
 	    ip_fib_local_table->tb_lookup(ip_fib_local_table, &fl, &res))
+#else
+	if (ip_fib_main_table->tb_lookup(ip_fib_main_table, &fl, &res))
+#endif
 		return NULL;
 	if (res.type != RTN_LOCAL)
 		goto out;
@@ -160,14 +163,20 @@ unsigned inet_addr_type(__be32 addr)
 	res.r = NULL;
 #endif
 
+#ifdef CONFIG_IP_MULTIPLE_TABLES
 	if (ip_fib_local_table) {
 		ret = RTN_UNICAST;
 		if (!ip_fib_local_table->tb_lookup(ip_fib_local_table,
 						   &fl, &res)) {
+#else
+	if (!ip_fib_main_table->tb_lookup(ip_fib_main_table, &fl, &res)) {
+#endif
 			ret = res.type;
 			fib_res_put(&res);
 		}
+#ifdef CONFIG_IP_MULTIPLE_TABLES
 	}
+#endif
 	return ret;
 }
 
@@ -624,6 +633,7 @@ static void fib_magic(int cmd, int type, __be32 dst, int dst_len, struct in_ifad
 		.fc_nlflags = NLM_F_CREATE | NLM_F_APPEND,
 	};
 
+#ifdef CONFIG_IP_MULTIPLE_TABLES
 	if (type == RTN_UNICAST)
 		tb = fib_new_table(RT_TABLE_MAIN);
 	else
@@ -631,6 +641,9 @@ static void fib_magic(int cmd, int type, __be32 dst, int dst_len, struct in_ifad
 
 	if (tb == NULL)
 		return;
+#else
+	tb = ip_fib_main_table;
+#endif
 
 	cfg.fc_table = tb->tb_id;
 
@@ -904,8 +917,6 @@ void __init ip_fib_init(void)
 	for (i = 0; i < FIB_TABLE_HASHSZ; i++)
 		INIT_HLIST_HEAD(&fib_table_hash[i]);
 #ifndef CONFIG_IP_MULTIPLE_TABLES
-	ip_fib_local_table = fib_hash_init(RT_TABLE_LOCAL);
-	hlist_add_head_rcu(&ip_fib_local_table->tb_hlist, &fib_table_hash[0]);
 	ip_fib_main_table  = fib_hash_init(RT_TABLE_MAIN);
 	hlist_add_head_rcu(&ip_fib_main_table->tb_hlist, &fib_table_hash[0]);
 #else
diff --git a/net/ipv4/fib_hash.c b/net/ipv4/fib_hash.c
index 9ad1d9f..5dfadab 100644
--- a/net/ipv4/fib_hash.c
+++ b/net/ipv4/fib_hash.c
@@ -241,7 +241,10 @@ fn_new_zone(struct fn_hash *table, int z)
 	return fz;
 }
 
-static int
+#ifdef CONFIG_IP_MULTIPLE_TABLES
+static
+#endif
+int
 fn_hash_lookup(struct fib_table *tb, const struct flowi *flp, struct fib_result *res)
 {
 	int err;
diff --git a/net/ipv4/fib_lef.c b/net/ipv4/fib_lef.c
new file mode 100644
index 0000000..677f7b5
--- /dev/null
+++ b/net/ipv4/fib_lef.c
@@ -0,0 +1,972 @@
+/*
+ *   This program is free software; you can redistribute it and/or
+ *   modify it under the terms of the GNU General Public License
+ *   as published by the Free Software Foundation; either version
+ *   2 of the License, or (at your option) any later version.
+ *
+ *   A modified radix based FIB implemetation by krichy (LEF)
+ */
+
+#include <asm/uaccess.h>
+#include <asm/system.h>
+#include <asm/bitops.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/mm.h>
+#include <linux/string.h>
+#include <linux/socket.h>
+#include <linux/sockios.h>
+#include <linux/errno.h>
+#include <linux/in.h>
+#include <linux/inet.h>
+#include <linux/inetdevice.h>
+#include <linux/netdevice.h>
+#include <linux/if_arp.h>
+#include <linux/proc_fs.h>
+#include <linux/rcupdate.h>
+#include <linux/skbuff.h>
+#include <linux/netlink.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <net/ip.h>
+#include <net/protocol.h>
+#include <net/route.h>
+#include <net/tcp.h>
+#include <net/sock.h>
+#include <net/ip_fib.h>
+#include "fib_lookup.h"
+
+/*
+ * a modified radix tree implemetation
+ */
+
+
+/* many code is borrowed from fib_radix, please, forgive me :) */
+
+#define	HBIT		0x80000000	// high bit
+
+#define BPS		4		// Bits Per Subtree
+
+#if defined(LITTLE_ENDIAN)
+
+#elif defined(BIG_ENDIAN) /* defined(LITTLE_ENDIAN) */
+
+#endif /* defined(BIG_ENDIAN) */
+
+#ifndef	EX_KEY
+#define EX_KEY(k)	(((k) >> (32 - BPS)) & (~((~0) << BPS)))
+#endif
+
+static struct kmem_cache*	fn_alias_kmem __read_mostly;
+
+static void __alias_free_mem(struct rcu_head *head)
+{
+	struct fib_alias *fa = container_of(head, struct fib_alias, rcu);
+	kmem_cache_free(fn_alias_kmem, fa);
+}
+
+static inline void alias_free_mem_rcu(struct fib_alias *fa)
+{
+	call_rcu(&fa->rcu, __alias_free_mem);
+}
+
+// forward declare radix_node
+struct radix_node;
+
+typedef struct lef_node {
+	struct lef_node		*child[1 << BPS];
+	struct lef_node		*parent;	// parent lef_node
+	struct lef_node		**pp;		// the pointer to us
+	struct radix_node	*rnode;		// the radix_node root
+	u8			key;
+	struct rcu_head		rcu;
+} lef_t;
+
+typedef struct radix_node {
+	struct list_head	falh;
+	struct radix_node	*l_child;	// left child  (0)
+	struct radix_node	*r_child;	// right child (1)
+	struct radix_node	*parent;	// parent
+	struct radix_node	**pp;		// parent's pointer to us
+	struct lef_node		*lparent;	// lef parent
+	struct rcu_head		rcu;
+} radix_t;
+
+// create a new lef node
+static inline lef_t		*new_lef_node(void)
+{
+	lef_t			*nl = kmalloc(sizeof(lef_t), GFP_KERNEL);
+
+	if (likely(nl)) {
+		memset(nl->child, 0, sizeof(nl->child));
+		nl->parent = NULL;
+		nl->pp = NULL;
+		nl->rnode = NULL;
+		nl->key = 0;
+		INIT_RCU_HEAD(&nl->rcu);
+	}
+
+	return nl;
+}
+
+// create a new node
+static inline radix_t		*new_radix_node(void)
+{
+	radix_t			*nn = kmalloc(sizeof(radix_t), GFP_KERNEL);
+	if (likely(nn)) {
+		nn->l_child = NULL;
+		nn->r_child = NULL;
+		nn->parent = NULL;
+		nn->pp = NULL;
+		nn->lparent = NULL;
+		INIT_LIST_HEAD(&nn->falh);
+		INIT_RCU_HEAD(&nn->rcu);
+	}
+	return nn;
+}
+
+// get a node and possibly create it
+static radix_t			*get_node(lef_t** p, u32 k, int klen)
+{
+	lef_t			*lp = NULL;	// lef parent
+	lef_t			*ln;		// lef node
+	radix_t			*rp;		// radix parent
+	radix_t			**rpp;		// radix parent's pointer to us
+	radix_t			*rn;		// radix node
+	u8			lkey = 0;
+
+	if (klen < 0 || klen > 32)
+		return NULL;
+
+	while( 1 ) {
+		ln = *p;
+
+		// we create the node if it does not exist
+		if (!ln) {
+			ln = new_lef_node();
+			if (unlikely(!ln))
+				return NULL;
+			ln->pp = p;
+			ln->key = lkey;
+
+			rcu_assign_pointer(ln->parent, lp);
+			rcu_assign_pointer(*p, ln);
+		}
+
+		if (klen < BPS)
+			break;
+
+		lkey = EX_KEY(k);
+		k <<= BPS;
+		klen -= BPS;
+
+		p = &ln->child[lkey];
+		lp = ln;
+	}
+
+	rp = NULL;
+	rpp = &ln->rnode;
+	while( 1 ) {
+		rn = *rpp;
+
+		if (!rn) {
+			rn = new_radix_node();
+			if (unlikely(!rn))
+				return NULL;
+			rn->pp = rpp;
+			rn->lparent = ln;
+
+			rcu_assign_pointer(rn->parent, rp);
+			rcu_assign_pointer(*rpp, rn);
+		}
+
+		if (klen == 0)
+			break;
+
+		if (k & HBIT)
+			rpp = &rn->r_child;
+		else
+			rpp = &rn->l_child;
+
+		rp = rn;
+		k <<= 1;
+		klen--;
+	}
+
+	return rn;
+}
+
+// insert a routing entry
+static int
+fn_lef_insert(struct fib_table* tb, struct fib_config *cfg)
+{
+	struct fib_alias	*fa, *new_fa;
+	struct fib_info		*fi;
+
+	int			plen = cfg->fc_dst_len;
+	u8			tos = cfg->fc_tos;
+	u32			key, mask;
+	int			err = 0;
+	radix_t*		n;
+
+	if (plen > 32)
+		return -EINVAL;
+
+	key = 0;
+	if (cfg->fc_dst)
+		key = ntohl(cfg->fc_dst);
+
+	mask = ntohl(inet_make_mask(plen));
+
+	if (key & ~mask)
+		return -EINVAL;
+
+	fi = fib_create_info(cfg);
+
+	if (IS_ERR(fi)) {
+		err = PTR_ERR(fi);
+		goto err;
+	}
+
+	n = get_node((lef_t**)tb->tb_data, key, plen);
+
+	if (unlikely(!n)) {
+		err = -ENOBUFS;
+		goto out;
+	}
+
+	fa = fib_find_alias(&n->falh, tos, fi->fib_priority);
+
+	/* Now fa, if non-NULL, points to the first fib alias
+	 * with the same keys [prefix,tos,priority], if such key already
+	 * exists or to the node before which we will insert new one.
+	 *
+	 * If fa is NULL, we will need to allocate a new one and
+	 * insert to the head of f.
+	 *
+	 * If f is NULL, no fib node matched the destination key
+	 * and we need to allocate a new one of those as well.
+	 */
+
+	if (fa && fa->fa_info->fib_priority == fi->fib_priority) {
+		struct fib_alias *fa_orig;
+
+		err = -EEXIST;
+		if (cfg->fc_nlflags & NLM_F_EXCL)
+			goto out;
+
+		if (cfg->fc_nlflags & NLM_F_REPLACE) {
+			struct fib_info *fi_drop;
+			u8 state;
+
+			err = -ENOBUFS;
+			new_fa = kmem_cache_alloc(fn_alias_kmem, GFP_KERNEL);
+			if (new_fa == NULL)
+				goto out;
+
+			fi_drop = fa->fa_info;
+			new_fa->fa_tos = fa->fa_tos;
+			new_fa->fa_info = fi;
+			new_fa->fa_type = cfg->fc_type;
+			new_fa->fa_scope = cfg->fc_scope;
+			state = fa->fa_state;
+			new_fa->fa_state &= ~FA_S_ACCESSED;
+
+			list_replace_rcu(&fa->fa_list, &new_fa->fa_list);
+			alias_free_mem_rcu(fa);
+
+			if (state & FA_S_ACCESSED)
+				rt_cache_flush(-1);
+			rtmsg_fib(RTM_NEWROUTE, htonl(key), new_fa, plen,
+				tb->tb_id, &cfg->fc_nlinfo, NLM_F_REPLACE);
+
+			goto succeeded;
+		}
+
+		/* Error if we find a perfect match which
+		 * uses the same scope, type, and nexthop
+		 * information.
+		 */
+		fa_orig = fa;
+		list_for_each_entry(fa, fa_orig->fa_list.prev, fa_list) {
+			if (fa->fa_tos != tos)
+				break;
+			if (fa->fa_info->fib_priority != fi->fib_priority)
+				break;
+			if (fa->fa_type == cfg->fc_type &&
+			    fa->fa_scope == cfg->fc_scope &&
+			    fa->fa_info == fi) {
+				goto out;
+			}
+		}
+		if (!(cfg->fc_nlflags & NLM_F_APPEND))
+			fa = fa_orig;
+	}
+	err = -ENOENT;
+	if (!(cfg->fc_nlflags & NLM_F_CREATE))
+		goto out;
+
+	err = -ENOBUFS;
+	new_fa = kmem_cache_alloc(fn_alias_kmem, GFP_KERNEL);
+	if (new_fa == NULL)
+		goto out;
+
+	new_fa->fa_info = fi;
+	new_fa->fa_tos = tos;
+	new_fa->fa_type = cfg->fc_type;
+	new_fa->fa_scope = cfg->fc_scope;
+	new_fa->fa_state = 0;
+
+	list_add_tail_rcu(&new_fa->fa_list, (fa ? &fa->fa_list : &n->falh));
+
+	rt_cache_flush(-1);
+	rtmsg_fib(RTM_NEWROUTE, htonl(key), new_fa, plen, tb->tb_id, &cfg->fc_nlinfo, 0);
+succeeded:
+	return 0;
+
+out:
+	fib_release_info(fi);
+err:
+	return err;
+}
+
+#ifdef CONFIG_IP_MULTIPLE_TABLES
+static
+#endif
+int
+fn_lef_lookup(struct fib_table *tb, const struct flowi *flp, struct fib_result *res)
+{
+	lef_t			*ln;		// current lef node
+	radix_t			*rn;		// current node
+	int			plen = 0;
+	u32			key = ntohl(flp->fl4_dst);
+	struct list_head	*fas[BPS+1];	// we collect all possible points here and start matching backwards
+	int			plens[BPS+1];
+#ifdef CONFIG_IP_ROUTE_MULTIPATH_CACHED
+	u32			mask = 0;	// mask is only needed when multipath caching is enabled
+						// read fib_semantic_match in fib_semantics.c
+	u32			masks[BPS+1];	// the mask for each possible node
+#endif
+	int			fap;
+	struct list_head	*fah;
+	int			err;
+
+	rcu_read_lock();
+
+	ln = rcu_dereference(*((lef_t**)tb->tb_data));
+
+	// first we walk down as deep as much we can
+	while ( ln ) {
+		lef_t	*next = ln->child[EX_KEY(key)];
+		if (!next)
+			break;
+
+		ln = next;
+		key <<= BPS;
+#ifdef CONFIG_IP_ROUTE_MULTIPATH_CACHED
+		mask = ~((~mask) >> BPS);
+#endif
+		plen += BPS;
+	}
+
+	// then we start walking the tree upwards
+	while ( ln ) {
+		u32 okey = key;	// orig key
+		rn = ln->rnode;
+		fap = 0;
+
+		while ( rn ) {
+			fah = &rn->falh;
+
+			if (!list_empty(fah)) {
+#ifdef CONFIG_IP_ROUTE_MULTIPATH_CACHED
+				masks[fap] = mask;
+#endif
+				plens[fap] = plen;
+				fas[fap++] = fah;
+			}
+
+			if (key & HBIT)
+				rn = rcu_dereference(rn->r_child);
+			else
+				rn = rcu_dereference(rn->l_child);
+
+#ifdef CONFIG_IP_ROUTE_MULTIPATH_CACHED
+			mask >>= 1;
+			mask |= HBIT;
+#endif
+			plen++;
+			key <<= 1;
+		}
+
+		while( --fap >= 0 ) {
+#ifdef CONFIG_IP_ROUTE_MULTIPATH_CACHED
+			if ((err = fib_semantic_match(fas[fap], flp, res, ntohl(flp->fl4_dst), masks[fap], plens[fap])) <= 0)
+#else
+			if ((err = fib_semantic_match(fas[fap], flp, res, 0, 0, plens[fap])) <= 0)
+#endif
+			{
+				rcu_read_unlock();
+				return err;
+			}
+		}
+
+		// restore key and step one up
+		key = (ln->key << (32 - BPS)) | (okey >> BPS);
+		ln = rcu_dereference(ln->parent);
+		plen -= BPS;
+#ifdef CONFIG_IP_ROUTE_MULTIPATH_CACHED
+		mask <<= BPS;
+#endif
+	}
+	rcu_read_unlock();
+
+	return 1;
+}
+
+static inline int	radix_node_has_refs(radix_t* n)
+{
+	return !list_empty(&n->falh) || n->l_child || n->r_child;
+}
+
+static inline int	lef_node_has_refs(const lef_t* l)
+{
+	int		i;
+
+	if (l->rnode)
+		return 1;
+	for (i=0; i<(1 << BPS); i++) {
+		if (l->child[i])
+			return 1;
+	}
+
+	return 0;
+}
+
+static void		__lef_delete_node(struct rcu_head *head)
+{
+	lef_t		*l = container_of(head, lef_t, rcu);
+
+	BUG_ON(lef_node_has_refs(l));
+
+	kfree(l);
+}
+
+static void		__radix_delete_node(struct rcu_head *head)
+{
+	radix_t*	n = container_of(head, radix_t, rcu);
+
+	BUG_ON(radix_node_has_refs(n));
+
+	kfree(n);
+}
+
+static inline void	lef_delete_node(lef_t *l)
+{
+	call_rcu(&l->rcu, __lef_delete_node);
+}
+
+static inline void	radix_delete_node(radix_t *s)
+{
+	call_rcu(&s->rcu, __radix_delete_node);
+}
+
+static void		lef_remove_node(lef_t *l)
+{
+	BUG_ON(!l);
+
+	rcu_assign_pointer(*(l->pp), NULL);
+
+	if (l->parent && !lef_node_has_refs(l->parent))
+		lef_remove_node(l->parent);
+
+	lef_delete_node(l);
+}
+
+static void		radix_remove_node(radix_t *n)
+{
+	BUG_ON(!n);
+
+	rcu_assign_pointer(*(n->pp), NULL);
+
+	if (n->parent && !radix_node_has_refs(n->parent))
+		radix_remove_node(n->parent);
+	if (!n->parent && n->lparent && !lef_node_has_refs(n->lparent))
+		lef_remove_node(n->lparent);
+
+	radix_delete_node(n);
+}
+
+static int
+fn_lef_delete(struct fib_table *tb, struct fib_config *cfg)
+{
+	// we do a lookup here, but only for a maximum depth
+	lef_t			*ln = *((lef_t**)tb->tb_data);
+	radix_t			*rn;
+	int			plen = cfg->fc_dst_len;
+	u32			key, mask;
+	struct list_head	*fa_head;
+	struct fib_alias	*fa, *fa_to_delete;
+
+	if (plen > 32)
+		return -EINVAL;
+
+	key = 0;
+	if (cfg->fc_dst)
+		key = ntohl(cfg->fc_dst);
+
+	mask = ntohl(inet_make_mask(plen));
+
+	if (key & ~mask)
+		return -EINVAL;
+
+	while ( ln && plen >= BPS ) {
+		ln=ln->child[EX_KEY(key)];
+		key <<= BPS;
+		plen -= BPS;
+	}
+
+	if (!ln)
+		return -ESRCH;
+
+	rn = ln->rnode;
+
+	while ( plen && rn ) {
+		if (key & HBIT)
+			rn = rn->r_child;
+		else
+			rn = rn->l_child;
+
+		key <<= 1;
+		plen--;
+	}
+
+	if (plen || !rn)
+		return -ESRCH;
+
+	fa_to_delete = NULL;
+	fa_head = &rn->falh;
+
+	list_for_each_entry(fa, fa_head, fa_list) {
+		struct fib_info *fi = fa->fa_info;
+
+		if (fa->fa_tos != cfg->fc_tos)
+			break;
+
+		if ((!cfg->fc_type ||
+		     fa->fa_type == cfg->fc_type) &&
+		    (cfg->fc_scope == RT_SCOPE_NOWHERE ||
+		     fa->fa_scope == cfg->fc_scope) &&
+		    (!cfg->fc_protocol ||
+		     fi->fib_protocol == cfg->fc_protocol) &&
+		    fib_nh_match(cfg, fi) == 0) {
+			fa_to_delete = fa;
+			break;
+		}
+	}
+
+	if (!fa_to_delete)
+		return -ESRCH;
+
+	fa = fa_to_delete;
+	rtmsg_fib(RTM_DELROUTE, htonl(key), fa, plen, tb->tb_id, &cfg->fc_nlinfo, 0);
+
+	list_del_rcu(&fa->fa_list);
+
+	// now the entry is removed, we must find the top-most node which can be removed
+	if (!radix_node_has_refs(rn))
+		radix_remove_node(rn);
+
+	if (fa->fa_state & FA_S_ACCESSED)
+		rt_cache_flush(-1);
+
+	fib_release_info(fa->fa_info);
+	alias_free_mem_rcu(fa);
+
+	return 0;
+}
+
+static int last_dflt = -1;
+
+static void
+fn_lef_select_default(struct fib_table *tb, const struct flowi *flp, struct fib_result *res)
+{
+	lef_t		*ln;
+	radix_t		*rn;
+	int order, last_idx;
+	struct fib_info *fi = NULL;
+	struct fib_info *last_resort;
+	struct fib_alias *fa = NULL;
+	struct list_head *fa_head;
+
+	last_idx = -1;
+	last_resort = NULL;
+	order = -1;
+
+	rcu_read_lock();
+
+	ln = rcu_dereference(*((lef_t**)tb->tb_data));
+	if (!ln)
+		goto out;
+
+	rn = rcu_dereference(ln->rnode);
+	if (!rn)
+		goto out;
+
+	fa_head = &rn->falh;
+
+	if (!fa_head)
+		goto out;
+
+	if (list_empty(fa_head))
+		goto out;
+
+	list_for_each_entry_rcu(fa, fa_head, fa_list) {
+		struct fib_info *next_fi = fa->fa_info;
+
+		if (fa->fa_scope != res->scope ||
+		    fa->fa_type != RTN_UNICAST)
+			continue;
+
+		if (next_fi->fib_priority > res->fi->fib_priority)
+			break;
+		if (!next_fi->fib_nh[0].nh_gw ||
+		    next_fi->fib_nh[0].nh_scope != RT_SCOPE_LINK)
+			continue;
+		fa->fa_state |= FA_S_ACCESSED;
+
+		if (fi == NULL) {
+			if (next_fi != res->fi)
+				break;
+		} else if (!fib_detect_death(fi, order, &last_resort,
+					     &last_idx, &last_dflt)) {
+			if (res->fi)
+				fib_info_put(res->fi);
+			res->fi = fi;
+			atomic_inc(&fi->fib_clntref);
+			last_dflt = order;
+			goto out;
+		}
+		fi = next_fi;
+		order++;
+	}
+	if (order <= 0 || fi == NULL) {
+		last_dflt = -1;
+		goto out;
+	}
+
+	if (!fib_detect_death(fi, order, &last_resort, &last_idx, &last_dflt)) {
+		if (res->fi)
+			fib_info_put(res->fi);
+		res->fi = fi;
+		atomic_inc(&fi->fib_clntref);
+		last_dflt = order;
+		goto out;
+	}
+	if (last_idx >= 0) {
+		if (res->fi)
+			fib_info_put(res->fi);
+		res->fi = last_resort;
+		if (last_resort)
+			atomic_inc(&last_resort->fib_clntref);
+	}
+	last_dflt = last_idx;
+ out:;
+	rcu_read_unlock();
+}
+
+#define BIT(i)  (HBIT >> (i-1))
+#define TB(v,i)	((v) & BIT(i))
+
+static int fn_lef_dump(struct fib_table *tb, struct sk_buff *skb, struct netlink_callback *cb)
+{
+	u32			key = cb->args[2];	// represents the actual key
+	u32			plen = cb->args[3];	// represents the actual key length
+	int			i;
+	struct list_head	*fah;
+	radix_t			*child;
+
+	radix_t			*rn;
+	radix_t			*nn;
+	lef_t			*ln;
+	lef_t			*lp;
+	u32			lef_key;
+	int			lpos = 0;
+
+	// pre-order tree traversal
+	rcu_read_lock();
+
+	// first of all we look for our node
+	ln = rcu_dereference(*((lef_t**)tb->tb_data));
+
+	i = 0;
+	lef_key = key;
+	while ( ln && (i+BPS <= plen) ) {
+		lef_t	*next = ln->child[EX_KEY(lef_key)];
+		if (!next)
+			break;
+
+		ln = next;
+		i += BPS;
+		lef_key <<= BPS;
+		lpos += BPS;
+	}
+
+	rn = ln ? ln->rnode : NULL;
+
+	if ( i+BPS <= plen || !rn ) { // unfortunately our node has disappeared
+		plen = i;
+	} else {
+		while( i < plen ) {
+			if (TB(key,i+1))
+				nn = rcu_dereference(rn->r_child);
+			else
+				nn = rcu_dereference(rn->l_child);
+			if (!nn)
+				break;
+			rn = nn;
+			i++;
+		}
+
+		plen = i;
+	}
+
+	key &= ntohl(inet_make_mask(plen));
+
+	// now we must continue pre-order traversal from n
+	while( ln ) {
+
+		while(rn) {
+			fah = &rn->falh;
+
+			if (!list_empty(fah)) {
+				int			fai = cb->args[4];
+				struct fib_alias	*fa;
+				u32			xkey = htonl(key);
+
+				i = 0;
+
+				list_for_each_entry_rcu(fa, fah, fa_list) {
+					if (i < fai) {
+						i++;
+						continue;
+					}
+
+					BUG_ON(!fa->fa_info);
+
+					if (fib_dump_info(skb, NETLINK_CB(cb->skb).pid,
+							  cb->nlh->nlmsg_seq,
+							  RTM_NEWROUTE,
+							  tb->tb_id,
+							  fa->fa_type,
+							  fa->fa_scope,
+							  xkey,
+							  plen,
+							  fa->fa_tos,
+							  fa->fa_info, 0) < 0) {
+
+						rcu_read_unlock();
+
+						cb->args[2] = key;
+						cb->args[3] = plen;
+						cb->args[4] = i;
+
+						return -1; // to indicate there is more data
+					}
+					i++;
+				}
+			}
+
+			// now must find next node to dump
+			cb->args[4] = 0;
+
+			if ((child = rcu_dereference(rn->l_child))) {
+				rn = child;
+				plen++;
+				WARN_ON(TB(key, plen));
+			} else if ((child = rcu_dereference(rn->r_child))) {
+				rn = child;
+				plen++;
+				WARN_ON(TB(key, plen));
+				key |= BIT(plen);	// set the last bit to 1
+			} else { // we must step upwards
+				radix_t*	p;
+				radix_t*	pr;
+
+				while((p = rcu_dereference(rn->parent))) {
+					pr = rcu_dereference(p->r_child);
+
+					if (pr != NULL && pr != rn)
+						break;
+
+					rn = p;
+					key &= ~BIT(plen); // set current bit to zero
+					plen--;
+				}
+
+				if (!p) {
+					break;
+				}
+
+				WARN_ON(TB(key, plen));	// it must be 0 now
+
+				rn = pr;
+				key |= BIT(plen);
+			}
+		}
+
+		WARN_ON(lpos != plen);
+
+		for (i = 0; i<(1 << BPS); i++) {
+			lef_t	*ch = rcu_dereference(ln->child[i]);
+
+			if (ch) {
+				// step down in lef tree
+				lpos += BPS;
+				plen += BPS;
+				key |= i << (32 - lpos);
+				ln = ch;
+				break;
+			}
+		}
+
+		if (i == (1 << BPS)) { // no child was found
+			while((lp = rcu_dereference(ln->parent))) {
+				key &= ~(((~0U) << (32-BPS)) >> (lpos - BPS));
+
+				WARN_ON(lp->child[ln->key] != ln);
+
+				for(i=ln->key + 1; i<(1 << BPS); i++) {
+					lef_t *ch = rcu_dereference(lp->child[i]);
+					if (ch) {
+						key |= i << (32 - lpos);
+						ln = ch;
+						break;
+					}
+				}
+				if (i < (1 << BPS))
+					break;
+
+				ln = lp;
+				lpos -= BPS;
+				plen -= BPS;
+			}
+			if (!lp)
+				break;
+		}
+
+		rn = ln->rnode;
+	}
+
+	rcu_read_unlock();
+
+	WARN_ON(plen != 0); // we should leave only if plen == 0
+
+	return skb->len;
+}
+
+static int	radix_flush_recursive(radix_t* n)
+{
+	struct fib_alias	*fa, *fa_node;
+	int			found = 0;
+
+	if (!n)
+		return 0;
+
+	found += radix_flush_recursive(n->l_child);
+	found += radix_flush_recursive(n->r_child);
+
+	list_for_each_entry_safe(fa, fa_node, &n->falh, fa_list) {
+		struct fib_info *fi = fa->fa_info;
+
+		if (fi && (fi->fib_flags & RTNH_F_DEAD)) {
+			list_del_rcu(&fa->fa_list);
+			fib_release_info(fa->fa_info);
+			alias_free_mem_rcu(fa);
+			found++;
+		}
+	}
+
+	if (!radix_node_has_refs(n)) { // dont delete parents, recursion will do that
+		rcu_assign_pointer(n->parent, NULL);
+		rcu_assign_pointer(n->lparent, NULL);
+		radix_remove_node(n);
+	}
+
+	return found;
+}
+
+static int	lef_flush_recursive(lef_t* l)
+{
+	int			i;
+	int			found = 0;
+
+	for (i=0; i<(1 << BPS); i++) {
+		if (l->child[i])
+			found += lef_flush_recursive(l->child[i]);
+	}
+	if (l->rnode)
+		found += radix_flush_recursive(l->rnode);
+
+	if (!lef_node_has_refs(l)) {
+		rcu_assign_pointer(l->parent, NULL); // skip recursion upwards
+		lef_remove_node(l);
+	}
+
+	return found;
+}
+
+static int	fn_lef_flush(struct fib_table *tb)
+{
+	lef_t*			l = *((lef_t**)tb->tb_data);
+	int			found = 0;
+
+	if (l)
+		found += lef_flush_recursive(l);
+
+	return found;
+}
+
+#ifdef CONFIG_IP_MULTIPLE_TABLES
+struct fib_table * fib_hash_init(u32 id)
+#else
+struct fib_table * __init fib_hash_init(u32 id)
+#endif
+{
+	struct fib_table *tb;
+
+	if (fn_alias_kmem == NULL)
+		fn_alias_kmem = kmem_cache_create("ip_fib_alias",
+						  sizeof(struct fib_alias),
+						  0, SLAB_HWCACHE_ALIGN,
+						  NULL);
+
+	tb = kmalloc(sizeof(struct fib_table) + sizeof(radix_t*),
+		     GFP_KERNEL);
+	if (tb == NULL)
+		return NULL;
+
+	tb->tb_id = id;
+	tb->tb_lookup = fn_lef_lookup;
+	tb->tb_insert = fn_lef_insert;
+	tb->tb_delete = fn_lef_delete;
+	tb->tb_flush = fn_lef_flush;
+	tb->tb_select_default = fn_lef_select_default;
+	tb->tb_dump = fn_lef_dump;
+	memset(tb->tb_data, 0, sizeof(radix_t*));
+
+	printk(KERN_INFO "IPv4 FIB: Using LEF for table %u\n", id);
+
+	return tb;
+}
+
+int __init fib_proc_init(void)
+{
+	return 0;
+}
+
+void __init fib_proc_exit(void)
+{
+}
+
diff --git a/net/ipv4/fib_semantics.c b/net/ipv4/fib_semantics.c
index c434119..dbdec07 100644
--- a/net/ipv4/fib_semantics.c
+++ b/net/ipv4/fib_semantics.c
@@ -152,6 +152,11 @@ void free_fib_info(struct fib_info *fi)
 		if (nh->nh_dev)
 			dev_put(nh->nh_dev);
 		nh->nh_dev = NULL;
+#ifdef CONFIG_IP_LEF
+		if (nh->neighbour)
+			neigh_release(nh->neighbour);
+		nh->neighbour = NULL;
+#endif
 	} endfor_nexthops(fi);
 	fib_info_cnt--;
 	kfree(fi);
@@ -861,13 +866,31 @@ failure:
 	return ERR_PTR(err);
 }
 
+#ifdef CONFIG_IP_LEF
+/* dst_hash - for hashing a flowi */
+static inline unsigned char __ip4_hash(const unsigned char *ip)
+{
+	return ip[0] + ip[1] + ip[2] + ip[3];
+}
+
+static inline unsigned char __flowi_hash(const struct flowi *flp)
+{
+	return __ip4_hash((unsigned char*)&flp->fl4_dst) +
+		jiffies;
+}
+#endif
+
 /* Note! fib_semantic_match intentionally uses  RCU list functions. */
 int fib_semantic_match(struct list_head *head, const struct flowi *flp,
 		       struct fib_result *res, __be32 zone, __be32 mask,
 			int prefixlen)
 {
 	struct fib_alias *fa;
-	int nh_sel = 0;
+	int nh_sel;
+#ifdef CONFIG_IP_LEF
+	const struct fib_nh *_nh;
+	unsigned _fib_nhs;
+#endif
 
 	list_for_each_entry_rcu(fa, head, fa_list) {
 		int err;
@@ -888,12 +911,51 @@ int fib_semantic_match(struct list_head *head, const struct flowi *flp,
 			if (fi->fib_flags & RTNH_F_DEAD)
 				continue;
 
+#ifdef CONFIG_IP_LEF
+			_fib_nhs = fi->fib_nhs;
+#endif
+
+#ifndef CONFIG_IP_LEF
 			switch (fa->fa_type) {
 			case RTN_UNICAST:
 			case RTN_LOCAL:
 			case RTN_BROADCAST:
 			case RTN_ANYCAST:
 			case RTN_MULTICAST:
+#endif
+#ifdef CONFIG_IP_LEF
+				{
+					int _nh_i;
+
+					if (likely(_fib_nhs == 1)) {
+						_nh = fi->fib_nh;
+						if (likely(!(_nh->nh_flags&RTNH_F_DEAD))) {
+							if (!flp->oif || flp->oif == _nh->nh_oif) {
+								nh_sel = 0;
+								goto out_fill_res;
+							}
+						}
+					} else {
+						nh_sel = ((unsigned)__flowi_hash(flp) % _fib_nhs);
+						for (_nh_i = 0; _nh_i < _fib_nhs; _nh_i++) {
+							_nh = fi->fib_nh + nh_sel;
+
+							if (likely(!(_nh->nh_flags&RTNH_F_DEAD))) {
+								if (!flp->oif || flp->oif == _nh->nh_oif)
+									break;
+							}
+							nh_sel = (nh_sel + 1) % _fib_nhs;
+						}
+					}
+#ifdef CONFIG_IP_ROUTE_MULTIPATH
+					if (_nh_i < _fib_nhs)
+						goto out_fill_res;
+#else
+					if (_nh_i < 1)
+						goto out_fill_res;
+#endif
+				}
+#else
 				for_nexthops(fi) {
 					if (nh->nh_flags&RTNH_F_DEAD)
 						continue;
@@ -911,12 +973,15 @@ int fib_semantic_match(struct list_head *head, const struct flowi *flp,
 				}
 #endif
 				endfor_nexthops(fi);
+#endif
 				continue;
+#ifndef CONFIG_IP_LEF
 
 			default:
 				printk(KERN_DEBUG "impossible 102\n");
 				return -EINVAL;
 			}
+#endif
 		}
 		return err;
 	}
@@ -928,6 +993,9 @@ out_fill_res:
 	res->type = fa->fa_type;
 	res->scope = fa->fa_scope;
 	res->fi = fa->fa_info;
+#ifdef CONFIG_IP_LEF
+	res->nh = (struct fib_nh*)_nh;
+#endif
 	atomic_inc(&res->fi->fib_clntref);
 	return 0;
 }
@@ -1058,6 +1126,9 @@ int fib_sync_down(__be32 local, struct net_device *dev, int force)
 		struct hlist_head *head = &fib_info_devhash[hash];
 		struct hlist_node *node;
 		struct fib_nh *nh;
+#ifdef CONFIG_IP_LEF
+		struct neighbour *neigh;
+#endif
 
 		hlist_for_each_entry(nh, node, head, nh_hash) {
 			struct fib_info *fi = nh->nh_parent;
@@ -1080,6 +1151,12 @@ int fib_sync_down(__be32 local, struct net_device *dev, int force)
 					nh->nh_power = 0;
 					spin_unlock_bh(&fib_multipath_lock);
 #endif
+#ifdef CONFIG_IP_LEF
+					if ((neigh = nh->neighbour)) {
+						nh->neighbour = NULL;
+						neigh_release(neigh);
+					}
+#endif
 					dead++;
 				}
 #ifdef CONFIG_IP_ROUTE_MULTIPATH
diff --git a/net/ipv4/fib_trie.c b/net/ipv4/fib_trie.c
index 9ca786a..c759fd6 100644
--- a/net/ipv4/fib_trie.c
+++ b/net/ipv4/fib_trie.c
@@ -1324,7 +1324,10 @@ static inline int check_leaf(struct trie *t, struct leaf *l,
 	return 1;
 }
 
-static int
+#ifdef CONFIG_IP_MULTIPLE_TABLES
+static
+#endif
+int
 fn_trie_lookup(struct fib_table *tb, const struct flowi *flp, struct fib_result *res)
 {
 	struct trie *t = (struct trie *) tb->tb_data;
diff --git a/net/ipv4/icmp.c b/net/ipv4/icmp.c
index 02a899b..799575a 100644
--- a/net/ipv4/icmp.c
+++ b/net/ipv4/icmp.c
@@ -440,8 +440,10 @@ void icmp_send(struct sk_buff *skb_in, int type, int code, __be32 info)
 	__be32 saddr;
 	u8  tos;
 
+#ifndef CONFIG_IP_LEF
 	if (!rt)
 		goto out;
+#endif
 
 	/*
 	 *	Find the original header. It is expected to be valid, of course.
@@ -463,7 +465,11 @@ void icmp_send(struct sk_buff *skb_in, int type, int code, __be32 info)
 	/*
 	 *	Now check at the protocol level
 	 */
+#ifdef CONFIG_IP_LEF
+	if (rt && rt->rt_flags & (RTCF_BROADCAST | RTCF_MULTICAST))
+#else
 	if (rt->rt_flags & (RTCF_BROADCAST | RTCF_MULTICAST))
+#endif
 		goto out;
 
 	/*
@@ -513,6 +519,11 @@ void icmp_send(struct sk_buff *skb_in, int type, int code, __be32 info)
 	 */
 
 	saddr = iph->daddr;
+#ifdef CONFIG_IP_LEF
+	if (!rt) {
+		saddr = 0;
+	} else
+#endif
 	if (!(rt->rt_flags & RTCF_LOCAL)) {
 		struct net_device *dev = NULL;
 
diff --git a/net/ipv4/ip_input.c b/net/ipv4/ip_input.c
index 9706939..45c751b 100644
--- a/net/ipv4/ip_input.c
+++ b/net/ipv4/ip_input.c
@@ -145,6 +145,9 @@
 #include <net/xfrm.h>
 #include <linux/mroute.h>
 #include <linux/netlink.h>
+#ifdef CONFIG_IP_LEF
+#include <net/lef.h>
+#endif
 
 /*
  *	SNMP management statistics
@@ -336,7 +339,11 @@ static inline int ip_rcv_finish(struct sk_buff *skb)
 	 *	how the packet travels inside Linux networking.
 	 */
 	if (skb->dst == NULL) {
-		int err = ip_route_input(skb, iph->daddr, iph->saddr, iph->tos,
+		int err;
+#ifdef CONFIG_IP_LEF
+		skb->lef.flags |= LEF_NEED;
+#endif
+		err = ip_route_input(skb, iph->daddr, iph->saddr, iph->tos,
 					 skb->dev);
 		if (unlikely(err)) {
 			if (err == -EHOSTUNREACH)
@@ -345,6 +352,10 @@ static inline int ip_rcv_finish(struct sk_buff *skb)
 				IP_INC_STATS_BH(IPSTATS_MIB_INNOROUTES);
 			goto drop;
 		}
+#ifdef CONFIG_IP_LEF
+		if (!skb->dst)	// LEF has processed the packet
+			return lef_forward(skb);
+#endif
 	}
 
 #ifdef CONFIG_NET_CLS_ROUTE
diff --git a/net/ipv4/lef.c b/net/ipv4/lef.c
new file mode 100644
index 0000000..b461f47
--- /dev/null
+++ b/net/ipv4/lef.c
@@ -0,0 +1,124 @@
+/*
+ * Linux express forwarding code
+ *
+ * Mainly developed by krichy < krichy at cflinux dot hu >
+ *
+ * Currently it is under development, so do not expect much from it,
+ * or not anything else than a kernel panic. :)
+ *
+ * The code is subject to GPLv2 or any later one.
+ */
+
+#include <linux/skbuff.h>
+#include <linux/netdevice.h>
+#include <net/arp.h>
+#include <net/lef.h>
+#include <net/sock.h>
+#include <net/ip.h>
+#include <net/route.h>
+#include <net/icmp.h>
+#include <linux/icmp.h>
+#include <linux/netfilter_ipv4.h>
+#include <linux/netfilter_bridge.h>
+
+static inline int	lef_output_finish2(struct sk_buff *skb)
+{
+	struct net_device *dev = skb->lef.dev;
+	struct neighbour *neigh;
+	int hh_len = LL_RESERVED_SPACE(dev);
+
+	/* Be paranoid, rather than too clever. */
+	if (unlikely(skb_headroom(skb) < hh_len && dev->hard_header)) {
+		struct sk_buff *skb2;
+
+		skb2 = skb_realloc_headroom(skb, LL_RESERVED_SPACE(dev));
+		if (skb2 == NULL) {
+			kfree_skb(skb);
+			return -ENOMEM;
+		}
+		if (skb->sk)
+			skb_set_owner_w(skb2, skb->sk);
+		kfree_skb(skb);
+		skb = skb2;
+	}
+
+	if (likely((neigh = skb->lef.neighbour))) {
+		return neigh->output(skb);
+	}
+
+	printk("lef_output_finish2: no neighbour found\n");
+	kfree_skb(skb);
+
+	return NET_RX_DROP;
+}
+
+static inline int	lef_output_finish(struct sk_buff *skb)
+{
+	if (skb->len > skb->lef.mtu && !skb_is_gso(skb)) {
+		// TODO: fragment
+		kfree_skb(skb);
+		return NET_RX_DROP;
+	} else {
+		return lef_output_finish2(skb);
+	}
+}
+
+static inline int	lef_output(struct sk_buff *skb)
+{
+	struct net_device *dev = skb->lef.dev;
+
+	IP_INC_STATS(IPSTATS_MIB_OUTREQUESTS);
+
+	skb->dev = dev;
+	skb->protocol = htons(ETH_P_IP);
+
+	return NF_HOOK_COND(PF_INET, NF_IP_POST_ROUTING, skb, NULL, dev,
+		            lef_output_finish,
+			    !(IPCB(skb)->flags & IPSKB_REROUTED));
+}
+
+static inline int	lef_forward_finish(struct sk_buff *skb)
+{
+	IP_INC_STATS_BH(IPSTATS_MIB_OUTFORWDATAGRAMS);
+
+	return lef_output(skb);
+}
+
+int			lef_forward(struct sk_buff *skb)
+{
+	struct iphdr *iph;	/* Our header */
+
+	if (skb->pkt_type != PACKET_HOST)
+		goto drop;
+
+	skb->ip_summed = CHECKSUM_NONE;
+	iph = ip_hdr(skb);
+
+	/*
+	 *	According to the RFC, we must first decrease the TTL field. If
+	 *	that reaches zero, we must reply an ICMP control message telling
+	 *	that the packet's lifetime expired.
+	 */
+	if (iph->ttl <= 1)
+                goto too_many_hops;
+
+	/* We are about to mangle packet. Copy it! */
+	if (skb_cow(skb, LL_RESERVED_SPACE(skb->lef.dev)))
+		goto drop;
+
+	/* Decrease ttl after skb cow done */
+	ip_decrease_ttl(iph);
+
+	skb->priority = rt_tos2priority(iph->tos);
+
+	return NF_HOOK(PF_INET, NF_IP_FORWARD, skb, skb->dev, skb->lef.dev,
+		       lef_forward_finish);
+
+too_many_hops:
+        /* Tell the sender its packet died... */
+        IP_INC_STATS_BH(IPSTATS_MIB_INHDRERRORS);
+        icmp_send(skb, ICMP_TIME_EXCEEDED, ICMP_EXC_TTL, 0);
+drop:
+	kfree_skb(skb);
+	return NET_RX_DROP;
+}
diff --git a/net/ipv4/netfilter/Kconfig b/net/ipv4/netfilter/Kconfig
index fa97947..774dd5b 100644
--- a/net/ipv4/netfilter/Kconfig
+++ b/net/ipv4/netfilter/Kconfig
@@ -197,7 +197,7 @@ config NF_NAT_NEEDED
 
 config IP_NF_TARGET_MASQUERADE
 	tristate "MASQUERADE target support"
-	depends on NF_NAT
+	depends on NF_NAT && !IP_LEF
 	help
 	  Masquerading is a special case of NAT: all outgoing connections are
 	  changed to seem to come from a particular interface's address, and
diff --git a/net/ipv4/route.c b/net/ipv4/route.c
index 198b732..3749df2 100644
--- a/net/ipv4/route.c
+++ b/net/ipv4/route.c
@@ -106,6 +106,9 @@
 #ifdef CONFIG_SYSCTL
 #include <linux/sysctl.h>
 #endif
+#ifdef CONFIG_IP_LEF
+#include <net/lef.h>
+#endif
 
 #define RT_FL_TOS(oldflp) \
     ((u32)(oldflp->fl4_tos & (IPTOS_RT_MASK | RTO_ONLINK)))
@@ -236,9 +239,14 @@ static spinlock_t	*rt_hash_locks;
 		for (i = 0; i < RT_HASH_LOCK_SZ; i++) \
 			spin_lock_init(&rt_hash_locks[i]); \
 		}
+static spinlock_t	_lef_fi_lock;
+# define lef_fi_lock_init() spin_lock_init(&_lef_fi_lock);
+# define lef_fi_lock &_lef_fi_lock
 #else
 # define rt_hash_lock_addr(slot) NULL
 # define rt_hash_lock_init()
+# define lef_fi_lock_init()
+# define lef_fi_lock NULL
 #endif
 
 static struct rt_hash_bucket 	*rt_hash_table;
@@ -250,6 +258,15 @@ static DEFINE_PER_CPU(struct rt_cache_stat, rt_cache_stat);
 #define RT_CACHE_STAT_INC(field) \
 	(__raw_get_cpu_var(rt_cache_stat).field++)
 
+#ifdef CONFIG_IP_LEF
+static inline int rt_intern_hash(unsigned hash, struct rtable *rth,
+				struct rtable **res);
+
+static inline unsigned int rt_hash_code(u32 daddr, u32 saddr)
+{
+	return 0;
+}
+#else
 static int rt_intern_hash(unsigned hash, struct rtable *rth,
 				struct rtable **res);
 
@@ -258,6 +275,7 @@ static unsigned int rt_hash_code(u32 daddr, u32 saddr)
 	return (jhash_2words(daddr, saddr, rt_hash_rnd)
 		& rt_hash_mask);
 }
+#endif
 
 #define rt_hash(daddr, saddr, idx) \
 	rt_hash_code((__force u32)(__be32)(daddr),\
@@ -832,6 +850,23 @@ work_done:
 out:	return 0;
 }
 
+#ifdef CONFIG_IP_LEF
+static inline int rt_intern_hash(unsigned hash, struct rtable *rt, struct rtable **rp)
+{
+	int err;
+
+	err = arp_bind_neighbour(&rt->u.dst);
+	if (err) {
+		rt_drop(rt);
+		return err;
+	}
+
+	rt_free(rt);
+	*rp = rt;
+
+	return 0;
+}
+#else
 static int rt_intern_hash(unsigned hash, struct rtable *rt, struct rtable **rp)
 {
 	struct rtable	*rth, **rthp;
@@ -957,6 +992,7 @@ restart:
 	*rp = rt;
 	return 0;
 }
+#endif
 
 void rt_bind_peer(struct rtable *rt, int create)
 {
@@ -1741,6 +1777,62 @@ static inline int ip_mkroute_input(struct sk_buff *skb,
 	return rt_intern_hash(hash, rth, (struct rtable**)&skb->dst);
 }
 
+#ifdef CONFIG_IP_LEF
+static inline int __lef_mkroute_input(struct sk_buff *skb, struct fib_result *res, __be32 daddr)
+{
+	int	err;
+	__be32	gw;
+
+	if (FIB_RES_GW(*res) && FIB_RES_NH(*res).nh_scope == RT_SCOPE_LINK)
+		gw = FIB_RES_GW(*res);
+	else
+		gw = daddr;
+
+	err = arp_bind_neighbour_lef(&skb->lef, gw);
+	if (unlikely(err))
+		return err;
+
+	if (gw != daddr) { // only store if it is a real gateway
+		spin_lock_bh(lef_fi_lock);
+		if (!res->nh->neighbour) {
+			rcu_assign_pointer(res->nh->neighbour, skb->lef.neighbour);
+			atomic_inc(&res->nh->neighbour->refcnt);
+		}
+		spin_unlock_bh(lef_fi_lock);
+	}
+
+	return 0;
+}
+
+static inline int lef_mkroute_input(struct sk_buff *skb, struct fib_result *res, struct in_device *in_dev, __be32 daddr)
+{
+	if (unlikely(!(skb->lef.flags & LEF_NEED)))
+		return -EAGAIN;
+
+	if (likely(ip_hdr(skb)->ihl <= 5 && !IN_DEV_RPFILTER(in_dev))) {
+		struct neighbour	*neigh;
+
+		skb->lef.dev = FIB_RES_DEV(*res);
+		dev_hold(skb->lef.dev);
+		skb->lef.mtu = res->fi->fib_mtu ? res->fi->fib_mtu : skb->lef.dev->mtu;
+
+		rcu_read_lock();
+		neigh = rcu_dereference(res->nh->neighbour);
+		if (likely(neigh)) {
+			skb->lef.neighbour = neigh;
+			atomic_inc(&neigh->refcnt);
+			rcu_read_unlock();
+			return 0;
+		} else {
+			rcu_read_unlock();
+			return __lef_mkroute_input(skb, res, daddr);
+		}
+	}
+
+	return -EAGAIN;
+}
+#endif
+
 /*
  *	NOTE. We drop all the packets that has local source
  *	addresses, because every properly looped back packet
@@ -1751,7 +1843,7 @@ static inline int ip_mkroute_input(struct sk_buff *skb,
  *	2. IP spoofing attempts are filtered with 100% of guarantee.
  */
 
-static int ip_route_input_slow(struct sk_buff *skb, __be32 daddr, __be32 saddr,
+static inline int ip_route_input_slow(struct sk_buff *skb, __be32 daddr, __be32 saddr,
 			       u8 tos, struct net_device *dev)
 {
 	struct fib_result res;
@@ -1829,6 +1921,11 @@ static int ip_route_input_slow(struct sk_buff *skb, __be32 daddr, __be32 saddr,
 	if (res.type != RTN_UNICAST)
 		goto martian_destination;
 
+#ifdef CONFIG_IP_LEF
+	err = lef_mkroute_input(skb, &res, in_dev, daddr);
+	if (likely(err != -EAGAIN))
+		goto done;
+#endif
 	err = ip_mkroute_input(skb, &res, &fl, in_dev, daddr, saddr, tos);
 	if (err == -ENOBUFS)
 		goto e_nobufs;
@@ -1936,11 +2033,14 @@ martian_source:
 int ip_route_input(struct sk_buff *skb, __be32 daddr, __be32 saddr,
 		   u8 tos, struct net_device *dev)
 {
+#ifndef CONFIG_IP_LEF
 	struct rtable * rth;
 	unsigned	hash;
 	int iif = dev->ifindex;
+#endif
 
 	tos &= IPTOS_RT_MASK;
+#ifndef CONFIG_IP_LEF
 	hash = rt_hash(daddr, saddr, iif);
 
 	rcu_read_lock();
@@ -1963,6 +2063,7 @@ int ip_route_input(struct sk_buff *skb, __be32 daddr, __be32 saddr,
 		RT_CACHE_STAT_INC(in_hlist_search);
 	}
 	rcu_read_unlock();
+#endif /* !CONFIG_IP_LEF */
 
 	/* Multicast recognition logic is moved from route cache to here.
 	   The problem was that too many Ethernet cards have broken/missing
@@ -2333,6 +2434,7 @@ out:	return err;
 
 int __ip_route_output_key(struct rtable **rp, const struct flowi *flp)
 {
+#ifndef CONFIG_IP_LEF
 	unsigned hash;
 	struct rtable *rth;
 
@@ -2359,6 +2461,7 @@ int __ip_route_output_key(struct rtable **rp, const struct flowi *flp)
 		RT_CACHE_STAT_INC(out_hlist_search);
 	}
 	rcu_read_unlock_bh();
+#endif
 
 	return ip_route_output_slow(rp, flp);
 }
@@ -3024,6 +3127,10 @@ int __init ip_rt_init(void)
 #endif
 	rtnl_register(PF_INET, RTM_GETROUTE, inet_rtm_getroute, NULL);
 
+#ifdef CONFIG_IP_LEF
+	lef_fi_lock_init();
+	printk(KERN_DEBUG "IPv4: LEF v0.2.1 is active\n");
+#endif
 	return rc;
 }
 
